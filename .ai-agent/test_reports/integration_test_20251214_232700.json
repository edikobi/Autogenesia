{
  "metadata": {
    "timestamp": "2025-12-14T23:27:00.300726",
    "project_dir": "C:\\Users\\Admin\\AI_Assistant_Pro",
    "user_query": "# ЗАДАЧА: Исправить app/history/compressor.py (Final Integration)Мы обнаружили, что в проекте уже есть готовые шаблоны промптов в `app/llm/prompt_templates.py`.Тебе нужно переписать `compressor.py`, используя их, вместо того чтобы писать промпты вручную. Это решит проблему с кавычками и дублированием кода.**Требования к реализации:**1.  **Импорты:**    *   `from app.llm.prompt_templates import format_compression_prompt`    *   `from app.history.storage import Message`    *   `from app.utils.token_counter import TokenCounter`    *   `from app.llm.api_client import call_llm`    *   `from config.settings import cfg`    *   Стандартные: `asyncio`, `logging`, `typing`, `dataclasses`.2.  **Функция `compress_history_if_needed(history, threshold)`:**    *   Логика та же: считаем токены, оставляем последние 3 сообщения без изменений.    *   Для сжатия используй `await call_llm(...)`.    *   **ВАЖНО:** Для формирования prompt'а используй импортированную функцию:        *   Для `role='assistant'`: `prompt = format_compression_prompt(msg.content, \"reasoning\")`        *   Для `role='tool'`: `prompt = format_compression_prompt(msg.content, \"tool_result\")`    *   Обрабатывай ошибки (try/except), возвращая оригинал при сбое.    *   Добавляй префикс `[COMPRESSED]`.3.  **Функция `prune_irrelevant_context(history, current_query)`:**    *   Реализуй логику поиска файлов в `current_query` (используй регулярки).    *   Если файлы найдены, проходи по `role='tool'` и заменяй контент на `[PRUNED: ...]`, если в нем нет упоминаний этих файлов.4.  **Безопасность (Safe Mode):**    *   В функции проверки блоков кода (`_contains_code_block`) **НЕ ИСПОЛЬЗУЙ** тройные кавычки в коде явно.    *   Используй `chr(96)*3` для проверки наличия маркдаун-блоков кода.**Выдай ПОЛНЫЙ код файла `compressor.py`.**",
    "duration_seconds": 130.7179343700409,
    "models_used": {
      "orchestrator": "Claude Sonnet 4.5 (RouterAI)",
      "code_generator": "deepseek-chat"
    }
  },
  "orchestrator": {
    "analysis": "The user wants to refactor `app/history/compressor.py` to use existing prompt templates from `app/llm/prompt_templates.py` instead of manually writing prompts. This will solve issues with quotes and code duplication.\n\nLooking at the selected chunks, I can see:\n- `format_compression_prompt` function exists in `app/llm/prompt_templates.py` and accepts `content` and `content_type` (\"tool_result\" or defaults to \"reasoning\")\n- `call_llm` function is available in `app/llm/api_client.py`\n- `Message` class is defined in `app/history/storage.py`\n- `TokenCounter` class exists in `app/utils/token_counter.py`\n\nThe current implementation needs to be completely rewritten to:\n1. Use the template functions instead of manual prompts\n2. Implement proper history compression with token counting\n3. Implement context pruning based on file mentions\n4. Use safe string handling for code block detection",
    "instruction": "**Task:** Completely rewrite the history compression module to use existing prompt templates and implement proper compression logic\n\n**File:** `app/history/compressor.py`\n\n**Location:** Replace entire file content\n\n**Changes:**\n\n1. **Add all required imports at the top of the file:**\n   - `import asyncio`\n   - `import logging`\n   - `import re`\n   - `from typing import List, Optional`\n   - `from dataclasses import dataclass`\n   - `from app.llm.prompt_templates import format_compression_prompt`\n   - `from app.history.storage import Message`\n   - `from app.utils.token_counter import TokenCounter`\n   - `from app.llm.api_client import call_llm`\n   - `from config.settings import cfg`\n\n2. **Create logger instance:**\n   - Add: `logger = logging.getLogger(__name__)`\n\n3. **Create helper function `_contains_code_block(content: str) -> bool`:**\n   - Use `chr(96)*3` to safely check for markdown code blocks (triple backticks)\n   - Return `True` if `chr(96)*3` is found in content, `False` otherwise\n   - This avoids using literal triple quotes in the code\n\n4. **Implement main function `async def compress_history_if_needed(history: List[Message], threshold: int = 8000) -> List[Message]`:**\n   - Initialize `TokenCounter()` instance\n   - Calculate total tokens: sum of `token_counter.count(msg.content)` for all messages in history\n   - If total tokens <= threshold, return history unchanged\n   - Create new list `compressed_history = []`\n   - Keep last 3 messages unchanged: `keep_last_n = 3`\n   - Split history into: `to_compress = history[:-keep_last_n]` and `keep_intact = history[-keep_last_n:]`\n   - For each message in `to_compress`:\n     - If `msg.role == 'user'`: append to compressed_history unchanged\n     - If `msg.role == 'assistant'`: call `await _compress_message(msg, \"reasoning\")`\n     - If `msg.role == 'tool'`: call `await _compress_message(msg, \"tool_result\")`\n     - Otherwise: append unchanged\n   - Extend compressed_history with keep_intact messages\n   - Log compression stats: original vs compressed token count\n   - Return compressed_history\n\n5. **Implement helper function `async def _compress_message(msg: Message, content_type: str) -> Message`:**\n   - Check if message already compressed: if `msg.content.startswith(\"[COMPRESSED]\")`, return msg unchanged\n   - Check if contains code blocks: if `_contains_code_block(msg.content)`, return msg unchanged (don't compress code)\n   - Use try-except block for compression:\n     - In try block:\n       - Get prompt: `prompt = format_compression_prompt(msg.content, content_type)`\n       - Get model: `model = cfg.AGENT_MODELS.get(\"history_compressor\", \"deepseek/deepseek-chat\")`\n       - Call LLM: `compressed = await call_llm(model=model, messages=[{\"role\": \"user\", \"content\": prompt}], temperature=0.0, max_tokens=2000)`\n       - Create new Message with compressed content: `content=\"[COMPRESSED] \" + compressed.strip()`\n       - Copy all other fields from original message (id, thread_id, role, tokens, metadata, created_at)\n       - Update tokens field with new token count\n       - Return new compressed message\n     - In except block:\n       - Log warning with exception details: `logger.warning(f\"Compression failed for {msg.role} message: {e}\")`\n       - Return original message unchanged\n\n6. **Implement function `def prune_irrelevant_context(history: List[Message], current_query: str) -> List[Message]`:**\n   - Extract file mentions from current_query using regex: `file_pattern = r'(?:^|[\\s,\\'\"(])([a-zA-Z0-9_/\\\\.-]+\\.(?:py|js|ts|sql|json|md|txt|html|css))(?:[\\s,\\'\")\\]]|$)'`\n   - Find all matches: `mentioned_files = set(re.findall(file_pattern, current_query))`\n   - If no files mentioned, return history unchanged\n   - Create `pruned_history = []`\n   - For each message in history:\n     - If `msg.role != 'tool'`: append unchanged\n     - If `msg.role == 'tool'`: check if any mentioned_file is in msg.content\n       - If yes: append unchanged\n       - If no: create new Message with `content=f\"[PRUNED: Tool output not relevant to {', '.join(mentioned_files)}]\"`\n       - Copy all other fields, update tokens count\n   - Return pruned_history\n\n7. **Add docstrings to all functions:**\n   - For `compress_history_if_needed`: Explain it compresses old messages using LLM while keeping last N intact\n   - For `_compress_message`: Explain it uses prompt templates to compress individual messages\n   - For `prune_irrelevant_context`: Explain it removes tool outputs not related to files mentioned in query\n   - For `_contains_code_block`: Explain it safely checks for markdown code blocks without using literal triple quotes\n\n**Why:** This refactoring eliminates code duplication by using centralized prompt templates, improves maintainability, fixes quote escaping issues, and implements proper history management with compression and pruning logic to reduce token usage while preserving important context."
  },
  "code_generator": {
    "code_blocks": [
      {
        "filepath": "app/history/compressor.py",
        "language": "python",
        "code": "\"\"\"\nМодуль для сжатия истории диалога на лету без сохранения в БД (режим Recompute).\nРеализует две основные стратегии:\n1. Токен-базированное сжатие: сжимает старые сообщения с помощью LLM,\n   сохраняя сообщения пользователя и блоки кода.\n2. Обрезка контекста: удаляет нерелевантные результаты инструментов на основе текущего запроса.\n\"\"\"\n\nimport asyncio\nimport logging\nimport re\nfrom typing import List, Optional\nfrom dataclasses import dataclass\nfrom app.llm.prompt_templates import format_compression_prompt\nfrom app.history.storage import Message\nfrom app.utils.token_counter import TokenCounter\nfrom app.llm.api_client import call_llm\nfrom config.settings import cfg\n\nlogger = logging.getLogger(__name__)\n\n\ndef _contains_code_block(content: str) -> bool:\n    \"\"\"\n    Безопасно проверяет, содержит ли текст блоки кода в формате Markdown (тройные обратные кавычки).\n    Использует chr(96)*3 для избежания проблем с экранированием кавычек в коде.\n\n    Args:\n        content: Текст для проверки.\n\n    Returns:\n        True, если текст содержит блоки кода, иначе False.\n    \"\"\"\n    triple_backticks = chr(96) * 3\n    return triple_backticks in content\n\n\nasync def compress_history_if_needed(history: List[Message], threshold: int = 8000) -> List[Message]:\n    \"\"\"\n    Сжимает историю сообщений, если общее количество токенов превышает пороговое значение.\n    Сохраняет последние N сообщений неизменными, а старые сообщения сжимает с помощью LLM.\n\n    Args:\n        history: Список сообщений для обработки.\n        threshold: Пороговое значение токенов для сжатия (по умолчанию 8000).\n\n    Returns:\n        Сжатый список сообщений или оригинальный список, если сжатие не требуется.\n    \"\"\"\n    token_counter = TokenCounter()\n    total_tokens = sum(token_counter.count(msg.content) for msg in history)\n    \n    if total_tokens <= threshold:\n        return history\n    \n    compressed_history = []\n    keep_last_n = 3\n    \n    # Разделяем историю на часть для сжатия и часть для сохранения\n    to_compress = history[:-keep_last_n] if len(history) > keep_last_n else []\n    keep_intact = history[-keep_last_n:] if len(history) > keep_last_n else history\n    \n    # Обрабатываем сообщения для сжатия\n    for msg in to_compress:\n        if msg.role == 'user':\n            compressed_history.append(msg)\n        elif msg.role == 'assistant':\n            compressed_msg = await _compress_message(msg, \"reasoning\")\n            compressed_history.append(compressed_msg)\n        elif msg.role == 'tool':\n            compressed_msg = await _compress_message(msg, \"tool_result\")\n            compressed_history.append(compressed_msg)\n        else:\n            compressed_history.append(msg)\n    \n    # Добавляем неизмененные последние сообщения\n    compressed_history.extend(keep_intact)\n    \n    # Логируем статистику сжатия\n    compressed_tokens = sum(token_counter.count(msg.content) for msg in compressed_history)\n    logger.info(f\"History compressed: {total_tokens} → {compressed_tokens} tokens \"\n                f\"({compressed_tokens/total_tokens*100:.1f}% of original)\")\n    \n    return compressed_history\n\n\nasync def _compress_message(msg: Message, content_type: str) -> Message:\n    \"\"\"\n    Сжимает отдельное сообщение с помощью LLM, используя шаблоны промптов.\n    Не сжимает уже сжатые сообщения или сообщения с блоками кода.\n\n    Args:\n        msg: Сообщение для сжатия.\n        content_type: Тип контента ('reasoning' или 'tool_result').\n\n    Returns:\n        Сжатое сообщение или оригинальное сообщение в случае ошибки.\n    \"\"\"\n    # Проверяем, не сжато ли сообщение уже\n    if msg.content.startswith(\"[COMPRESSED]\"):\n        return msg\n    \n    # Не сжимаем сообщения с блоками кода\n    if _contains_code_block(msg.content):\n        return msg\n    \n    try:\n        # Форматируем промпт для сжатия\n        prompt = format_compression_prompt(msg.content, content_type)\n        \n        # Получаем модель для сжатия\n        model = cfg.AGENT_MODELS.get(\"history_compressor\", \"deepseek/deepseek-chat\")\n        \n        # Вызываем LLM для сжатия\n        compressed = await call_llm(\n            model=model,\n            messages=[{\"role\": \"user\", \"content\": prompt}],\n            temperature=0.0,\n            max_tokens=2000\n        )\n        \n        # Создаем новое сжатое сообщение\n        compressed_content = \"[COMPRESSED] \" + compressed.strip()\n        \n        # Копируем все поля из оригинального сообщения\n        compressed_msg = Message(\n            id=msg.id,\n            thread_id=msg.thread_id,\n            role=msg.role,\n            content=compressed_content,\n            tokens=TokenCounter().count(compressed_content),\n            metadata=msg.metadata,\n            created_at=msg.created_at\n        )\n        \n        return compressed_msg\n        \n    except Exception as e:\n        logger.warning(f\"Compression failed for {msg.role} message: {e}\")\n        return msg\n\n\ndef prune_irrelevant_context(history: List[Message], current_query: str) -> List[Message]:\n    \"\"\"\n    Удаляет нерелевантные результаты инструментов из истории на основе файлов,\n    упомянутых в текущем запросе.\n\n    Args:\n        history: История сообщений для обработки.\n        current_query: Текущий запрос пользователя.\n\n    Returns:\n        История с удаленными нерелевантными результатами инструментов.\n    \"\"\"\n    # Извлекаем упомянутые файлы из текущего запроса\n    file_pattern = r'(?:^|[\\s,\\'\"(])([a-zA-Z0-9_/\\\\.-]+\\.(?:py|js|ts|sql|json|md|txt|html|css))(?:[\\s,\\'\")\\]]|$)'\n    mentioned_files = set(re.findall(file_pattern, current_query))\n    \n    # Если файлы не упомянуты, возвращаем историю без изменений\n    if not mentioned_files:\n        return history\n    \n    pruned_history = []\n    \n    for msg in history:\n        if msg.role != 'tool':\n            pruned_history.append(msg)\n        else:\n            # Проверяем, содержит ли результат инструмента упомянутые файлы\n            if any(mentioned_file in msg.content for mentioned_file in mentioned_files):\n                pruned_history.append(msg)\n            else:\n                # Заменяем нерелевантный результат инструмента\n                pruned_content = f\"[PRUNED: Tool output not relevant to {', '.join(mentioned_files)}]\"\n                pruned_msg = Message(\n                    id=msg.id,\n                    thread_id=msg.thread_id,\n                    role=msg.role,\n                    content=pruned_content,\n                    tokens=TokenCounter().count(pruned_content),\n                    metadata=msg.metadata,\n                    created_at=msg.created_at\n                )\n                pruned_history.append(pruned_msg)\n    \n    return pruned_history",
        "context": null
      },
      {
        "filepath": "app/history/compressor.py",
        "language": "python",
        "code": "compressed_history = await compress_history_if_needed(history, threshold=8000)",
        "context": null
      },
      {
        "filepath": "app/history/compressor.py",
        "language": "python",
        "code": "pruned_history = prune_irrelevant_context(history, current_query)",
        "context": null
      }
    ],
    "explanation": "Этот код полностью переписывает модуль сжатия истории диалога, реализуя улучшенную архитектуру с использованием существующих шаблонов промптов и правильной логики сжатия.\n\n**Что делает код:**\n\n1. **Импорты и настройка**:\n   - Добавлены все необходимые импорты, включая `asyncio` для асинхронных операций\n   - Создан логгер для отслеживания операций сжатия\n\n2. **Вспомогательная функция `_contains_code_block`**:\n   - Безопасно проверяет наличие блоков кода в формате Markdown (тройные обратные кавычки)\n   - Использует `chr(96)*3` вместо литеральных кавычек для избежания проблем с экранированием\n\n3. **Основная функция `compress_history_if_needed`**:\n   - Рассчитывает общее количество токенов в истории\n   - Если токены не превышают порог (по умолчанию 8000), возвращает историю без изменений\n   - Сохраняет последние 3 сообщения неизменными для поддержания контекста\n   - Разделяет историю на часть для сжатия и часть для сохранения\n   - Обрабатывает разные типы сообщений:\n     - Сообщения пользователя остаются неизменными\n     - Сообщения ассистента сжимаются как \"reasoning\"\n     - Результаты инструментов сжимаются как \"tool_result\"\n   - Логирует статистику сжатия (исходные и сжатые токены)\n\n4. **Функция `_compress_message`**:\n   - Проверяет, не сжато ли сообщение уже (по префиксу \"[COMPRESSED]\")\n   - Не сжимает сообщения с блоками кода для сохранения важной информации\n   - Использует централизованные шаблоны промптов через `format_compression_prompt`\n   - Вызывает LLM для сжатия контента с низкой температурой (0.0) для детерминированных результатов\n   - Обрабатывает ошибки сжатия, возвращая оригинальное сообщение в случае проблем\n\n5. **Функция `prune_irrelevant_context`**:\n   - Извлекает упомянутые файлы из текущего запроса пользователя с помощью регулярного выражения\n   - Удаляет нерелевантные результаты инструментов, которые не содержат упомянутых файлов\n   - Заменяет удаленный контент информативным сообщением о причине удаления\n   - Сохраняет все другие типы сообщений без изменений\n\n**Почему этот подход работает:**\n\n1. **Использование существующих промптов**: Устраняет дублирование кода и обеспечивает согласованность форматов сжатия\n2. **Асинхронная архитектура**: Позволяет эффективно обрабатывать сжатие без блокировки основного потока\n3. **Сохранение контекста**: Последние сообщения остаются неизменными для поддержания актуального диалога\n4. **Безопасная обработка кода**: Блоки кода не сжимаются, что предотвращает потерю важной технической информации\n5. **Адаптивная обрезка**: Удаляет только нерелевантные результаты инструментов на основе текущего запроса\n\n**Как использовать:**\n\n1. Для сжатия истории при превышении лимита токенов:\n   \n\n2. Для удаления нерелевантного контекста:\n   \n\n**Важные замечания:**\n\n- Модуль использует асинхронные вызовы LLM, поэтому функции должны вызываться с `await`\n- Сжатые сообщения помечаются префиксом \"[COMPRESSED]\" для предотвращения повторного сжатия\n- Порог сжатия (8000 токенов) можно настраивать в зависимости от требований модели\n- Функция обрезки работает только с результатами инструментов, сохраняя все другие типы сообщений\n- В случае ошибок сжатия модуль возвращает оригинальные сообщения, обеспечивая отказоустойчивость",
    "frontend_json": {
      "success": true,
      "code_blocks": [
        {
          "code": "\"\"\"\nМодуль для сжатия истории диалога на лету без сохранения в БД (режим Recompute).\nРеализует две основные стратегии:\n1. Токен-базированное сжатие: сжимает старые сообщения с помощью LLM,\n   сохраняя сообщения пользователя и блоки кода.\n2. Обрезка контекста: удаляет нерелевантные результаты инструментов на основе текущего запроса.\n\"\"\"\n\nimport asyncio\nimport logging\nimport re\nfrom typing import List, Optional\nfrom dataclasses import dataclass\nfrom app.llm.prompt_templates import format_compression_prompt\nfrom app.history.storage import Message\nfrom app.utils.token_counter import TokenCounter\nfrom app.llm.api_client import call_llm\nfrom config.settings import cfg\n\nlogger = logging.getLogger(__name__)\n\n\ndef _contains_code_block(content: str) -> bool:\n    \"\"\"\n    Безопасно проверяет, содержит ли текст блоки кода в формате Markdown (тройные обратные кавычки).\n    Использует chr(96)*3 для избежания проблем с экранированием кавычек в коде.\n\n    Args:\n        content: Текст для проверки.\n\n    Returns:\n        True, если текст содержит блоки кода, иначе False.\n    \"\"\"\n    triple_backticks = chr(96) * 3\n    return triple_backticks in content\n\n\nasync def compress_history_if_needed(history: List[Message], threshold: int = 8000) -> List[Message]:\n    \"\"\"\n    Сжимает историю сообщений, если общее количество токенов превышает пороговое значение.\n    Сохраняет последние N сообщений неизменными, а старые сообщения сжимает с помощью LLM.\n\n    Args:\n        history: Список сообщений для обработки.\n        threshold: Пороговое значение токенов для сжатия (по умолчанию 8000).\n\n    Returns:\n        Сжатый список сообщений или оригинальный список, если сжатие не требуется.\n    \"\"\"\n    token_counter = TokenCounter()\n    total_tokens = sum(token_counter.count(msg.content) for msg in history)\n    \n    if total_tokens <= threshold:\n        return history\n    \n    compressed_history = []\n    keep_last_n = 3\n    \n    # Разделяем историю на часть для сжатия и часть для сохранения\n    to_compress = history[:-keep_last_n] if len(history) > keep_last_n else []\n    keep_intact = history[-keep_last_n:] if len(history) > keep_last_n else history\n    \n    # Обрабатываем сообщения для сжатия\n    for msg in to_compress:\n        if msg.role == 'user':\n            compressed_history.append(msg)\n        elif msg.role == 'assistant':\n            compressed_msg = await _compress_message(msg, \"reasoning\")\n            compressed_history.append(compressed_msg)\n        elif msg.role == 'tool':\n            compressed_msg = await _compress_message(msg, \"tool_result\")\n            compressed_history.append(compressed_msg)\n        else:\n            compressed_history.append(msg)\n    \n    # Добавляем неизмененные последние сообщения\n    compressed_history.extend(keep_intact)\n    \n    # Логируем статистику сжатия\n    compressed_tokens = sum(token_counter.count(msg.content) for msg in compressed_history)\n    logger.info(f\"History compressed: {total_tokens} → {compressed_tokens} tokens \"\n                f\"({compressed_tokens/total_tokens*100:.1f}% of original)\")\n    \n    return compressed_history\n\n\nasync def _compress_message(msg: Message, content_type: str) -> Message:\n    \"\"\"\n    Сжимает отдельное сообщение с помощью LLM, используя шаблоны промптов.\n    Не сжимает уже сжатые сообщения или сообщения с блоками кода.\n\n    Args:\n        msg: Сообщение для сжатия.\n        content_type: Тип контента ('reasoning' или 'tool_result').\n\n    Returns:\n        Сжатое сообщение или оригинальное сообщение в случае ошибки.\n    \"\"\"\n    # Проверяем, не сжато ли сообщение уже\n    if msg.content.startswith(\"[COMPRESSED]\"):\n        return msg\n    \n    # Не сжимаем сообщения с блоками кода\n    if _contains_code_block(msg.content):\n        return msg\n    \n    try:\n        # Форматируем промпт для сжатия\n        prompt = format_compression_prompt(msg.content, content_type)\n        \n        # Получаем модель для сжатия\n        model = cfg.AGENT_MODELS.get(\"history_compressor\", \"deepseek/deepseek-chat\")\n        \n        # Вызываем LLM для сжатия\n        compressed = await call_llm(\n            model=model,\n            messages=[{\"role\": \"user\", \"content\": prompt}],\n            temperature=0.0,\n            max_tokens=2000\n        )\n        \n        # Создаем новое сжатое сообщение\n        compressed_content = \"[COMPRESSED] \" + compressed.strip()\n        \n        # Копируем все поля из оригинального сообщения\n        compressed_msg = Message(\n            id=msg.id,\n            thread_id=msg.thread_id,\n            role=msg.role,\n            content=compressed_content,\n            tokens=TokenCounter().count(compressed_content),\n            metadata=msg.metadata,\n            created_at=msg.created_at\n        )\n        \n        return compressed_msg\n        \n    except Exception as e:\n        logger.warning(f\"Compression failed for {msg.role} message: {e}\")\n        return msg\n\n\ndef prune_irrelevant_context(history: List[Message], current_query: str) -> List[Message]:\n    \"\"\"\n    Удаляет нерелевантные результаты инструментов из истории на основе файлов,\n    упомянутых в текущем запросе.\n\n    Args:\n        history: История сообщений для обработки.\n        current_query: Текущий запрос пользователя.\n\n    Returns:\n        История с удаленными нерелевантными результатами инструментов.\n    \"\"\"\n    # Извлекаем упомянутые файлы из текущего запроса\n    file_pattern = r'(?:^|[\\s,\\'\"(])([a-zA-Z0-9_/\\\\.-]+\\.(?:py|js|ts|sql|json|md|txt|html|css))(?:[\\s,\\'\")\\]]|$)'\n    mentioned_files = set(re.findall(file_pattern, current_query))\n    \n    # Если файлы не упомянуты, возвращаем историю без изменений\n    if not mentioned_files:\n        return history\n    \n    pruned_history = []\n    \n    for msg in history:\n        if msg.role != 'tool':\n            pruned_history.append(msg)\n        else:\n            # Проверяем, содержит ли результат инструмента упомянутые файлы\n            if any(mentioned_file in msg.content for mentioned_file in mentioned_files):\n                pruned_history.append(msg)\n            else:\n                # Заменяем нерелевантный результат инструмента\n                pruned_content = f\"[PRUNED: Tool output not relevant to {', '.join(mentioned_files)}]\"\n                pruned_msg = Message(\n                    id=msg.id,\n                    thread_id=msg.thread_id,\n                    role=msg.role,\n                    content=pruned_content,\n                    tokens=TokenCounter().count(pruned_content),\n                    metadata=msg.metadata,\n                    created_at=msg.created_at\n                )\n                pruned_history.append(pruned_msg)\n    \n    return pruned_history",
          "filepath": "app/history/compressor.py",
          "language": "python",
          "context": null
        },
        {
          "code": "compressed_history = await compress_history_if_needed(history, threshold=8000)",
          "filepath": "app/history/compressor.py",
          "language": "python",
          "context": null
        },
        {
          "code": "pruned_history = prune_irrelevant_context(history, current_query)",
          "filepath": "app/history/compressor.py",
          "language": "python",
          "context": null
        }
      ],
      "combined_code": "\n\n# ==================================================# filepath: app/history/compressor.py\n\n\"\"\"\nМодуль для сжатия истории диалога на лету без сохранения в БД (режим Recompute).\nРеализует две основные стратегии:\n1. Токен-базированное сжатие: сжимает старые сообщения с помощью LLM,\n   сохраняя сообщения пользователя и блоки кода.\n2. Обрезка контекста: удаляет нерелевантные результаты инструментов на основе текущего запроса.\n\"\"\"\n\nimport asyncio\nimport logging\nimport re\nfrom typing import List, Optional\nfrom dataclasses import dataclass\nfrom app.llm.prompt_templates import format_compression_prompt\nfrom app.history.storage import Message\nfrom app.utils.token_counter import TokenCounter\nfrom app.llm.api_client import call_llm\nfrom config.settings import cfg\n\nlogger = logging.getLogger(__name__)\n\n\ndef _contains_code_block(content: str) -> bool:\n    \"\"\"\n    Безопасно проверяет, содержит ли текст блоки кода в формате Markdown (тройные обратные кавычки).\n    Использует chr(96)*3 для избежания проблем с экранированием кавычек в коде.\n\n    Args:\n        content: Текст для проверки.\n\n    Returns:\n        True, если текст содержит блоки кода, иначе False.\n    \"\"\"\n    triple_backticks = chr(96) * 3\n    return triple_backticks in content\n\n\nasync def compress_history_if_needed(history: List[Message], threshold: int = 8000) -> List[Message]:\n    \"\"\"\n    Сжимает историю сообщений, если общее количество токенов превышает пороговое значение.\n    Сохраняет последние N сообщений неизменными, а старые сообщения сжимает с помощью LLM.\n\n    Args:\n        history: Список сообщений для обработки.\n        threshold: Пороговое значение токенов для сжатия (по умолчанию 8000).\n\n    Returns:\n        Сжатый список сообщений или оригинальный список, если сжатие не требуется.\n    \"\"\"\n    token_counter = TokenCounter()\n    total_tokens = sum(token_counter.count(msg.content) for msg in history)\n    \n    if total_tokens <= threshold:\n        return history\n    \n    compressed_history = []\n    keep_last_n = 3\n    \n    # Разделяем историю на часть для сжатия и часть для сохранения\n    to_compress = history[:-keep_last_n] if len(history) > keep_last_n else []\n    keep_intact = history[-keep_last_n:] if len(history) > keep_last_n else history\n    \n    # Обрабатываем сообщения для сжатия\n    for msg in to_compress:\n        if msg.role == 'user':\n            compressed_history.append(msg)\n        elif msg.role == 'assistant':\n            compressed_msg = await _compress_message(msg, \"reasoning\")\n            compressed_history.append(compressed_msg)\n        elif msg.role == 'tool':\n            compressed_msg = await _compress_message(msg, \"tool_result\")\n            compressed_history.append(compressed_msg)\n        else:\n            compressed_history.append(msg)\n    \n    # Добавляем неизмененные последние сообщения\n    compressed_history.extend(keep_intact)\n    \n    # Логируем статистику сжатия\n    compressed_tokens = sum(token_counter.count(msg.content) for msg in compressed_history)\n    logger.info(f\"History compressed: {total_tokens} → {compressed_tokens} tokens \"\n                f\"({compressed_tokens/total_tokens*100:.1f}% of original)\")\n    \n    return compressed_history\n\n\nasync def _compress_message(msg: Message, content_type: str) -> Message:\n    \"\"\"\n    Сжимает отдельное сообщение с помощью LLM, используя шаблоны промптов.\n    Не сжимает уже сжатые сообщения или сообщения с блоками кода.\n\n    Args:\n        msg: Сообщение для сжатия.\n        content_type: Тип контента ('reasoning' или 'tool_result').\n\n    Returns:\n        Сжатое сообщение или оригинальное сообщение в случае ошибки.\n    \"\"\"\n    # Проверяем, не сжато ли сообщение уже\n    if msg.content.startswith(\"[COMPRESSED]\"):\n        return msg\n    \n    # Не сжимаем сообщения с блоками кода\n    if _contains_code_block(msg.content):\n        return msg\n    \n    try:\n        # Форматируем промпт для сжатия\n        prompt = format_compression_prompt(msg.content, content_type)\n        \n        # Получаем модель для сжатия\n        model = cfg.AGENT_MODELS.get(\"history_compressor\", \"deepseek/deepseek-chat\")\n        \n        # Вызываем LLM для сжатия\n        compressed = await call_llm(\n            model=model,\n            messages=[{\"role\": \"user\", \"content\": prompt}],\n            temperature=0.0,\n            max_tokens=2000\n        )\n        \n        # Создаем новое сжатое сообщение\n        compressed_content = \"[COMPRESSED] \" + compressed.strip()\n        \n        # Копируем все поля из оригинального сообщения\n        compressed_msg = Message(\n            id=msg.id,\n            thread_id=msg.thread_id,\n            role=msg.role,\n            content=compressed_content,\n            tokens=TokenCounter().count(compressed_content),\n            metadata=msg.metadata,\n            created_at=msg.created_at\n        )\n        \n        return compressed_msg\n        \n    except Exception as e:\n        logger.warning(f\"Compression failed for {msg.role} message: {e}\")\n        return msg\n\n\ndef prune_irrelevant_context(history: List[Message], current_query: str) -> List[Message]:\n    \"\"\"\n    Удаляет нерелевантные результаты инструментов из истории на основе файлов,\n    упомянутых в текущем запросе.\n\n    Args:\n        history: История сообщений для обработки.\n        current_query: Текущий запрос пользователя.\n\n    Returns:\n        История с удаленными нерелевантными результатами инструментов.\n    \"\"\"\n    # Извлекаем упомянутые файлы из текущего запроса\n    file_pattern = r'(?:^|[\\s,\\'\"(])([a-zA-Z0-9_/\\\\.-]+\\.(?:py|js|ts|sql|json|md|txt|html|css))(?:[\\s,\\'\")\\]]|$)'\n    mentioned_files = set(re.findall(file_pattern, current_query))\n    \n    # Если файлы не упомянуты, возвращаем историю без изменений\n    if not mentioned_files:\n        return history\n    \n    pruned_history = []\n    \n    for msg in history:\n        if msg.role != 'tool':\n            pruned_history.append(msg)\n        else:\n            # Проверяем, содержит ли результат инструмента упомянутые файлы\n            if any(mentioned_file in msg.content for mentioned_file in mentioned_files):\n                pruned_history.append(msg)\n            else:\n                # Заменяем нерелевантный результат инструмента\n                pruned_content = f\"[PRUNED: Tool output not relevant to {', '.join(mentioned_files)}]\"\n                pruned_msg = Message(\n                    id=msg.id,\n                    thread_id=msg.thread_id,\n                    role=msg.role,\n                    content=pruned_content,\n                    tokens=TokenCounter().count(pruned_content),\n                    metadata=msg.metadata,\n                    created_at=msg.created_at\n                )\n                pruned_history.append(pruned_msg)\n    \n    return pruned_history\n\n# filepath: app/history/compressor.py\n\ncompressed_history = await compress_history_if_needed(history, threshold=8000)\n\n# filepath: app/history/compressor.py\n\npruned_history = prune_irrelevant_context(history, current_query)",
      "explanation": "Этот код полностью переписывает модуль сжатия истории диалога, реализуя улучшенную архитектуру с использованием существующих шаблонов промптов и правильной логики сжатия.\n\n**Что делает код:**\n\n1. **Импорты и настройка**:\n   - Добавлены все необходимые импорты, включая `asyncio` для асинхронных операций\n   - Создан логгер для отслеживания операций сжатия\n\n2. **Вспомогательная функция `_contains_code_block`**:\n   - Безопасно проверяет наличие блоков кода в формате Markdown (тройные обратные кавычки)\n   - Использует `chr(96)*3` вместо литеральных кавычек для избежания проблем с экранированием\n\n3. **Основная функция `compress_history_if_needed`**:\n   - Рассчитывает общее количество токенов в истории\n   - Если токены не превышают порог (по умолчанию 8000), возвращает историю без изменений\n   - Сохраняет последние 3 сообщения неизменными для поддержания контекста\n   - Разделяет историю на часть для сжатия и часть для сохранения\n   - Обрабатывает разные типы сообщений:\n     - Сообщения пользователя остаются неизменными\n     - Сообщения ассистента сжимаются как \"reasoning\"\n     - Результаты инструментов сжимаются как \"tool_result\"\n   - Логирует статистику сжатия (исходные и сжатые токены)\n\n4. **Функция `_compress_message`**:\n   - Проверяет, не сжато ли сообщение уже (по префиксу \"[COMPRESSED]\")\n   - Не сжимает сообщения с блоками кода для сохранения важной информации\n   - Использует централизованные шаблоны промптов через `format_compression_prompt`\n   - Вызывает LLM для сжатия контента с низкой температурой (0.0) для детерминированных результатов\n   - Обрабатывает ошибки сжатия, возвращая оригинальное сообщение в случае проблем\n\n5. **Функция `prune_irrelevant_context`**:\n   - Извлекает упомянутые файлы из текущего запроса пользователя с помощью регулярного выражения\n   - Удаляет нерелевантные результаты инструментов, которые не содержат упомянутых файлов\n   - Заменяет удаленный контент информативным сообщением о причине удаления\n   - Сохраняет все другие типы сообщений без изменений\n\n**Почему этот подход работает:**\n\n1. **Использование существующих промптов**: Устраняет дублирование кода и обеспечивает согласованность форматов сжатия\n2. **Асинхронная архитектура**: Позволяет эффективно обрабатывать сжатие без блокировки основного потока\n3. **Сохранение контекста**: Последние сообщения остаются неизменными для поддержания актуального диалога\n4. **Безопасная обработка кода**: Блоки кода не сжимаются, что предотвращает потерю важной технической информации\n5. **Адаптивная обрезка**: Удаляет только нерелевантные результаты инструментов на основе текущего запроса\n\n**Как использовать:**\n\n1. Для сжатия истории при превышении лимита токенов:\n   \n\n2. Для удаления нерелевантного контекста:\n   \n\n**Важные замечания:**\n\n- Модуль использует асинхронные вызовы LLM, поэтому функции должны вызываться с `await`\n- Сжатые сообщения помечаются префиксом \"[COMPRESSED]\" для предотвращения повторного сжатия\n- Порог сжатия (8000 токенов) можно настраивать в зависимости от требований модели\n- Функция обрезки работает только с результатами инструментов, сохраняя все другие типы сообщений\n- В случае ошибок сжатия модуль возвращает оригинальные сообщения, обеспечивая отказоустойчивость",
      "error": null,
      "model_used": "deepseek-chat",
      "tokens_used": 0
    }
  }
}