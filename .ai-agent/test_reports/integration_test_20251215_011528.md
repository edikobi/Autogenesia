# ü§ñ AI Code Agent - –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏–æ–Ω–Ω—ã–π –¢–µ—Å—Ç

**–î–∞—Ç–∞ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è:** 15.12.2025 01:15:28
**–ü—Ä–æ–µ–∫—Ç:** `C:\Users\Admin\AI_Assistant_Pro`
**–í—Ä–µ–º—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è:** 148.25 —Å–µ–∫.

---

## üìù –ó–∞–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è

> # –ó–ê–î–ê–ß–ê: –ò—Å–ø—Ä–∞–≤–∏—Ç—å –æ—à–∏–±–∫–∏ –≤ —Å–∫—Ä–∏–ø—Ç–µ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è scripts/test_history_manager.py–°–∫—Ä–∏–ø—Ç –ø–∞–¥–∞–µ—Ç –∏–∑-–∑–∞ –Ω–µ–ø—Ä–∞–≤–∏–ª—å–Ω—ã—Ö –∏–º–µ–Ω –∞—Ä–≥—É–º–µ–Ω—Ç–æ–≤ –ø—Ä–∏ –≤—ã–∑–æ–≤–µ —Ñ—É–Ω–∫—Ü–∏–π. –ö–æ–¥ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è (`app/history/...`) –º–µ–Ω—è—Ç—å –Ω–µ–ª—å–∑—è, –Ω—É–∂–Ω–æ –∏—Å–ø—Ä–∞–≤–∏—Ç—å —Ç–æ–ª—å–∫–æ —Å–∞–º —Ç–µ—Å—Ç.**–ò—Å–ø—Ä–∞–≤–ª–µ–Ω–∏—è:**1.  **–í —Ñ—É–Ω–∫—Ü–∏–∏ `test_history_compression`:**    –ù–∞–π–¥–∏ –≤—ã–∑–æ–≤ `compress_history_if_needed`.    –ó–∞–º–µ–Ω–∏ –∞—Ä–≥—É–º–µ–Ω—Ç `token_threshold` –Ω–∞ `threshold` (—Ç–∞–∫ –æ–Ω –Ω–∞–∑—ã–≤–∞–µ—Ç—Å—è –≤ compressor.py).2.  **–í —Ñ—É–Ω–∫—Ü–∏–∏ `test_prune_context`:**    –ù–∞–π–¥–∏ –≤—ã–∑–æ–≤ `prune_irrelevant_context`.    –ó–∞–º–µ–Ω–∏ –∞—Ä–≥—É–º–µ–Ω—Ç `messages` –Ω–∞ `history`.    –ó–∞–º–µ–Ω–∏ –∞—Ä–≥—É–º–µ–Ω—Ç `user_query` –Ω–∞ `current_query`.3.  **–í —Ñ—É–Ω–∫—Ü–∏–∏ `cleanup_test_database`:**    –ü–µ—Ä–µ–¥ —É–¥–∞–ª–µ–Ω–∏–µ–º —Ñ–∞–π–ª–∞ –¥–æ–±–∞–≤—å:    ```    import gc    gc.collect() # Force garbage collection to close DB handles    await asyncio.sleep(0.5) # Give Windows time to release file lock    ```    (–ù–µ –∑–∞–±—É–¥—å –¥–æ–±–∞–≤–∏—Ç—å `async` –∫ —Ñ—É–Ω–∫—Ü–∏–∏ `cleanup_test_database` –∏ `await` –ø—Ä–∏ –µ—ë –≤—ã–∑–æ–≤–µ –≤ `main`).**–í—ã–¥–∞–π –ø–æ–ª–Ω—ã–π –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–Ω—ã–π –∫–æ–¥ —Ñ–∞–π–ª–∞ `scripts/test_history_manager.py`.**

---

## üéØ –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–Ω—ã–µ –º–æ–¥–µ–ª–∏

- **Orchestrator:** Claude Sonnet 4.5 (RouterAI)
- **Code Generator:** deepseek-chat

---

## üîç –ê–Ω–∞–ª–∏–∑ –û—Ä–∫–µ—Å—Ç—Ä–∞—Ç–æ—Ä–∞

The test script `scripts/test_history_manager.py` has three critical issues:

1. **Line 258-261**: `compress_history_if_needed` is called with incorrect parameter names:
   - Uses `messages=` instead of `history=`
   - Uses `token_threshold=` instead of `threshold=`

2. **Line 319-322**: `prune_irrelevant_context` is called with incorrect parameter names:
   - Uses `messages=` instead of `history=`
   - Uses `user_query=` instead of `current_query=`

3. **Line 356-372**: The `cleanup_test_database` function attempts to delete a database file that may still be locked by SQLite connections on Windows. This requires:
   - Converting the function to `async` 
   - Adding `gc.collect()` to force garbage collection
   - Adding `await asyncio.sleep(0.5)` to give Windows time to release the file lock
   - Updating the call in `main()` to use `await`

---

## üìã –ò–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏ –¥–ª—è Code Generator

**Task:** Fix incorrect function argument names and add async cleanup for database file handling

**File:** `scripts/test_history_manager.py`

**Changes:**

1. **Line 1 (imports section)**: Add `gc` import after `asyncio`:
   ```python
   import gc
   ```

2. **Line 258-261 (in `test_history_compression` function)**: Replace the `compress_history_if_needed` call with corrected parameter names:
   - Change `messages=messages` to `history=messages`
   - Change `token_threshold=2000` to `threshold=2000`
   
   The corrected call should be:
   ```python
   compression_result = await compress_history_if_needed(
       history=messages,
       threshold=2000
   )
   ```

3. **Line 319-322 (in `test_prune_context` function)**: Replace the `prune_irrelevant_context` call with corrected parameter names:
   - Change `messages=messages` to `history=messages`
   - Change `user_query=user_query` to `current_query=user_query`
   
   The corrected call should be:
   ```python
   pruned_messages = prune_irrelevant_context(
       history=messages,
       current_query=user_query
   )
   ```

4. **Line 356 (function signature)**: Change `cleanup_test_database()` to async:
   - Change `def cleanup_test_database() -> bool:` to `async def cleanup_test_database() -> bool:`

5. **Line 362-364 (in `cleanup_test_database` function, before `db_path.unlink()`)**: Add garbage collection and sleep to release file locks:
   ```python
   gc.collect()  # Force garbage collection to close DB handles
   await asyncio.sleep(0.5)  # Give Windows time to release file lock
   db_path.unlink()
   ```

6. **Line 435 (in `main` function)**: Change the cleanup call to use `await`:
   - Change `test_results["cleanup"] = cleanup_test_database()` to `test_results["cleanup"] = await cleanup_test_database()`

**Why:** 
- The function parameter names in the test don't match the actual signatures in `app/history/compressor.py`, causing runtime errors
- Windows file locking requires explicit garbage collection and a delay to properly release SQLite database connections before deletion
- Making `cleanup_test_database` async allows proper use of `await asyncio.sleep()` for the file lock delay

---

## üíª –°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –∫–æ–¥

**–§–∞–π–ª:** `scripts/test_history_manager.py`

```python
import asyncio
import logging
import sys
from pathlib import Path
from datetime import datetime
from typing import List, Dict, Any, Tuple
import traceback
import gc

# Add project root to sys.path for imports
project_root = Path(__file__).resolve().parent.parent
if str(project_root) not in sys.path:
    sys.path.insert(0, str(project_root))

# Project-specific imports
from app.history.manager import HistoryManager
from app.history.storage import HistoryStorage, Thread, Message
from app.history.compressor import compress_history_if_needed, prune_irrelevant_context
from app.utils.token_counter import TokenCounter
from config.settings import Config


def setup_logging() -> None:
    """Configure colored logging with timestamps."""
    # Custom log level for success
    SUCCESS_LEVEL_NUM = 25
    logging.addLevelName(SUCCESS_LEVEL_NUM, "SUCCESS")

    def success(self, message, *args, **kwargs):
        if self.isEnabledFor(SUCCESS_LEVEL_NUM):
            self._log(SUCCESS_LEVEL_NUM, message, args, **kwargs)

    logging.Logger.success = success

    # Color codes
    COLORS = {
        'INFO': '\033[96m',      # Cyan
        'WARNING': '\033[93m',   # Yellow
        'ERROR': '\033[91m',     # Red
        'SUCCESS': '\033[92m',   # Green
        'RESET': '\033[0m',      # Reset
    }

    class ColoredFormatter(logging.Formatter):
        def format(self, record):
            levelname = record.levelname
            if levelname in COLORS:
                levelname_color = f"{COLORS[levelname]}{levelname}{COLORS['RESET']}"
                record.levelname = levelname_color
            return super().format(record)

    # Configure handler
    handler = logging.StreamHandler()
    formatter = ColoredFormatter(
        '[%(asctime)s] [%(levelname)s] %(message)s',
        datefmt='%Y-%m-%d %H:%M:%S'
    )
    handler.setFormatter(formatter)

    # Configure root logger
    logger = logging.getLogger()
    logger.setLevel(logging.DEBUG)
    logger.addHandler(handler)

    logging.info("Logging configured successfully")


def test_imports() -> bool:
    """Test all required imports."""
    logger = logging.getLogger(__name__)
    logger.info("Testing imports...")

    imports_to_test = [
        ("app.history.manager", "HistoryManager"),
        ("app.history.storage", "HistoryStorage, Thread, Message"),
        ("app.history.compressor", "compress_history_if_needed, prune_irrelevant_context"),
        ("app.utils.token_counter", "TokenCounter"),
        ("config.settings", "Config"),
    ]

    all_successful = True

    for module_path, import_names in imports_to_test:
        try:
            __import__(module_path)
            logger.info(f"‚úì Import successful: {module_path} -> {import_names}")
        except ImportError as e:
            logger.error(f"‚úó Import failed for {module_path}: {e}")
            all_successful = False
        except Exception as e:
            logger.error(f"‚úó Unexpected error importing {module_path}: {e}")
            all_successful = False

    if all_successful:
        logger.success("All imports successful")
    else:
        logger.error("Some imports failed")

    return all_successful


async def test_api_connection() -> bool:
    """Test API connection for history compression."""
    logger = logging.getLogger(__name__)
    logger.info("Testing API connection for history compression...")

    try:
        # Import here to avoid circular dependencies
        from app.llm.api_client import call_llm

        # Get model from config
        model = getattr(Config, 'COMPRESSOR_MODEL', 'deepseek-chat')

        # Prepare test message
        messages = [{"role": "user", "content": "test"}]

        logger.debug(f"Calling LLM API with model: {model}")

        # Call API
        response = await call_llm(
            model=model,
            messages=messages,
            temperature=0.1,
            max_tokens=50
        )

        # Extract response content
        if hasattr(response, 'content'):
            content = response.content
        elif isinstance(response, dict) and 'content' in response:
            content = response['content']
        else:
            content = str(response)

        preview = content[:50] + "..." if len(content) > 50 else content
        logger.success(f"API connection successful. Response preview: {preview}")
        return True

    except ImportError as e:
        logger.error(f"Failed to import api_client: {e}")
        return False
    except ConnectionError as e:
        logger.error(f"Connection error: {e}")
        return False
    except TimeoutError as e:
        logger.error(f"Timeout error: {e}")
        return False
    except Exception as e:
        logger.exception(f"Unexpected error during API test: {e}")
        return False


def test_create_history() -> Tuple[str, HistoryManager]:
    """Create a new conversation thread with test messages."""
    logger = logging.getLogger(__name__)
    logger.info("Creating new conversation thread...")

    try:
        # Ensure tests directory exists
        db_path = Path("tests/test_history.db")
        db_path.parent.mkdir(parents=True, exist_ok=True)

        # Initialize HistoryManager with test database
        manager = HistoryManager(db_path=str(db_path))

        # Create new thread
        thread = manager.create_thread(
            user_id="test_user",
            project_path="test_project",
            project_name="Test Project"
        )

        thread_id = thread.id
        logger.info(f"Thread created with ID: {thread_id}")

        # Assert thread_id is not None
        assert thread_id is not None, "Thread ID should not be None"
        logger.debug(f"Assertion passed: thread_id = {thread_id}")

        # Add test messages
        test_messages = [
            {"role": "user", "content": "Hello, can you help me with my project?"},
            {"role": "assistant", "content": "Of course! I'd be happy to help. What's your project about?"},
            {"role": "user", "content": "It's a web application using FastAPI and React."},
            {"role": "assistant", "content": "Great choice! FastAPI is excellent for backend APIs."},
            {"role": "user", "content": "I need help with authentication setup."},
        ]

        for i, msg_data in enumerate(test_messages, 1):
            message = manager.add_message(
                thread_id=thread_id,
                role=msg_data["role"],
                content=msg_data["content"]
            )
            logger.info(f"Added message {i}/{len(test_messages)}: {message.id}")

        # Verify message count
        messages = manager.get_session_history(thread_id)
        assert len(messages) == len(test_messages), \
            f"Expected {len(test_messages)} messages, got {len(messages)}"
        logger.debug(f"Assertion passed: {len(messages)} messages added")

        # Get thread statistics
        stats = manager.get_thread_statistics(thread_id)
        logger.info(f"Thread statistics: {stats.get('total_messages', 0)} messages, "
                   f"{stats.get('total_tokens', 0)} tokens")

        logger.success("Thread creation test completed successfully")
        return thread_id, manager

    except FileNotFoundError as e:
        logger.error(f"Database file not found: {e}")
        raise
    except ValueError as e:
        logger.error(f"Invalid value: {e}")
        raise
    except Exception as e:
        logger.exception(f"Unexpected error in thread creation: {e}")
        raise


async def test_history_compression(manager: HistoryManager, thread_id: str) -> Dict[str, Any]:
    """Test dynamic history compression."""
    logger = logging.getLogger(__name__)
    logger.info("Testing dynamic history compression...")

    try:
        # Get initial messages
        messages = manager.get_session_history(thread_id)
        initial_count = len(messages)

        # Calculate initial tokens (simplified)
        token_counter = TokenCounter()
        initial_tokens = sum(token_counter.count(msg.content) for msg in messages)

        logger.info(f"Initial state: {initial_count} messages, ~{int(initial_tokens)} tokens")

        # Add more messages to trigger compression
        logger.info("Adding messages to trigger compression threshold...")
        long_content = "This is a long message " * 20  # ~200 tokens

        for i in range(1, 11):
            role = "user" if i % 2 == 1 else "assistant"
            manager.add_message(
                thread_id=thread_id,
                role=role,
                content=f"{long_content} - Message {i}"
            )
            logger.debug(f"Added long message {i}/10")

        # Get updated messages
        messages = manager.get_session_history(thread_id)
        before_count = len(messages)
        before_tokens = sum(token_counter.count(msg.content) for msg in messages)

        logger.info(f"Before compression: {before_count} messages, ~{int(before_tokens)} tokens")

        # Apply compression
        compression_result = await compress_history_if_needed(
            history=messages,
            threshold=2000
        )

        after_count = len(compression_result.get("compressed_messages", []))
        after_tokens = compression_result.get("total_tokens_after", 0)
        pruned_count = compression_result.get("pruned_count", 0)

        logger.info(f"After compression: {after_count} messages, ~{int(after_tokens)} tokens")
        logger.info(f"Pruned {pruned_count} messages")

        # Verify compression occurred
        compression_happened = (after_tokens < before_tokens) or (after_count < before_count)
        assert compression_happened, "Compression should reduce tokens or message count"

        if compression_happened:
            logger.success("Compression test passed successfully")
        else:
            logger.warning("No compression happened - might be below threshold")

        return {
            "before_count": before_count,
            "before_tokens": before_tokens,
            "after_count": after_count,
            "after_tokens": after_tokens,
            "pruned_count": pruned_count,
            "compression_happened": compression_happened
        }

    except AssertionError as e:
        logger.error(f"Assertion failed: {e}")
        raise
    except Exception as e:
        logger.exception(f"Unexpected error in compression test: {e}")
        raise


def test_prune_context() -> Dict[str, Any]:
    """Test context pruning for irrelevant tool results."""
    logger = logging.getLogger(__name__)
    logger.info("Testing context pruning for irrelevant tool results...")

    try:
        # Create test messages with tool results
        messages = [
            Message(id="1", thread_id="test", role="user", content="Show me the auth service code", tokens=0),
            Message(id="2", thread_id="test", role="tool", content="File: app/services/auth.py\nCode: def authenticate(): ...", tokens=0),
            Message(id="3", thread_id="test", role="tool", content="File: app/utils/logger.py\nCode: def log(): ...", tokens=0),
            Message(id="4", thread_id="test", role="tool", content="File: app/models/user.py\nCode: class User: ...", tokens=0),
            Message(id="5", thread_id="test", role="assistant", content="Here's the auth service code...", tokens=0),
            Message(id="6", thread_id="test", role="user", content="Now modify only app/services/auth.py", tokens=0),
        ]

        original_count = len(messages)
        logger.info(f"Original messages: {original_count}")

        # User query mentioning specific file
        user_query = "Modify the authenticate function in app/services/auth.py"

        # Apply pruning
        pruned_messages = prune_irrelevant_context(
            history=messages,
            current_query=user_query
        )

        pruned_count = len(pruned_messages)
        logger.info(f"After pruning: {pruned_count} messages")
        logger.info(f"Removed {original_count - pruned_count} irrelevant messages")

        # Verify irrelevant tool results were removed
        tool_messages_before = [m for m in messages if m.role == "tool"]
        tool_messages_after = [m for m in pruned_messages if m.role == "tool"]

        # Check that only auth.py tool result remains
        auth_tools = [m for m in tool_messages_after if "auth.py" in m.content]
        other_tools = [m for m in tool_messages_after if "auth.py" not in m.content]

        assert len(other_tools) == 0, "Irrelevant tool results should be removed"
        assert len(auth_tools) > 0, "Relevant tool results should remain"

        logger.success("Context pruning test passed successfully")

        return {
            "original_count": original_count,
            "pruned_count": pruned_count,
            "removed_count": original_count - pruned_count,
            "files_mentioned": ["app/services/auth.py"]
        }

    except AssertionError as e:
        logger.error(f"Assertion failed: {e}")
        raise
    except Exception as e:
        logger.exception(f"Unexpected error in pruning test: {e}")
        raise


async def cleanup_test_database() -> bool:
    """Clean up test database file."""
    logger = logging.getLogger(__name__)
    logger.info("Cleaning up test database...")

    try:
        db_path = Path("tests/test_history.db")
        if db_path.exists():
            gc.collect()  # Force garbage collection to close DB handles
            await asyncio.sleep(0.5)  # Give Windows time to release file lock
            db_path.unlink()
            logger.success(f"Removed test database: {db_path}")
            return True
        else:
            logger.info("Test database does not exist, nothing to clean up")
            return True
    except Exception as e:
        logger.error(f"Failed to clean up test database: {e}")
        return False


async def main() -> int:
    """Main test runner."""
    print("\n" + "=" * 40)
    print("=== HISTORY MANAGEMENT TEST SUITE ===")
    print("=" * 40 + "\n")

    # Setup logging
    setup_logging()
    logger = logging.getLogger(__name__)

    # Test results tracker
    test_results = {}

    try:
        # Test 1: Imports
        logger.info("Starting test: Imports")
        test_results["imports"] = test_imports()

        if not test_results["imports"]:
            logger.error("Import test failed. Skipping further tests.")
            return 1

        # Test 2: API Connection
        logger.info("Starting test: API Connection")
        test_results["api_connection"] = await test_api_connection()

        if not test_results["api_connection"]:
            logger.warning("API connection test failed. Some tests may be limited.")

        # Test 3: Create History
        logger.info("Starting test: Create History")
        try:
            thread_id, manager = test_create_history()
            test_results["create_history"] = True
        except Exception:
            test_results["create_history"] = False
            thread_id, manager = None, None

        # Test 4: History Compression (if history created successfully)
        if test_results.get("create_history") and thread_id and manager:
            logger.info("Starting test: History Compression")
            try:
                compression_stats = await test_history_compression(manager, thread_id)
                test_results["history_compression"] = compression_stats.get("compression_happened", False)
            except Exception:
                test_results["history_compression"] = False
        else:
            logger.warning("Skipping compression test - history creation failed")
            test_results["history_compression"] = False

        # Test 5: Prune Context
        logger.info("Starting test: Prune Context")
        try:
            prune_stats = test_prune_context()
            test_results["prune_context"] = prune_stats.get("removed_count", 0) > 0
        except Exception:
            test_results["prune_context"] = False

        # Cleanup
        logger.info("Starting cleanup")
        test_results["cleanup"] = await cleanup_test_database()

    except KeyboardInterrupt:
        logger.error("Test suite interrupted by user")
        return 1
    except Exception as e:
        logger.exception(f"Unexpected error in main test runner: {e}")
        return 1

    # Print summary
    print("\n" + "=" * 40)
    print("=== TEST RESULTS ===")
    print("=" * 40)

    passed = sum(1 for result in test_results.values() if result is True)
    total = sum(1 for result in test_results.values() if isinstance(result, bool))

    print(f"\nSummary: {passed}/{total} tests passed")

    for test_name, result in test_results.items():
        status = "‚úì PASS" if result else "‚úó FAIL"
        color = '\033[92m' if result else '\033[91m'
        reset = '\033[0m'
        print(f"  {color}{status}{reset}: {test_name}")

    print("\n" + "=" * 40)

    # Return exit code
    if passed == total:
        logger.success("All tests passed!")
        return 0
    else:
        logger.error(f"{total - passed} test(s) failed")
        return 1


if __name__ == "__main__":
    exit_code = asyncio.run(main())
    sys.exit(exit_code)
```

---

## üìñ –ü–æ—è—Å–Ω–µ–Ω–∏—è –∫ –∫–æ–¥—É

–≠—Ç–æ—Ç –∫–æ–¥ –≤–Ω–æ—Å–∏—Ç –Ω–µ—Å–∫–æ–ª—å–∫–æ –≤–∞–∂–Ω—ã—Ö –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–π –≤ —Ç–µ—Å—Ç–æ–≤—ã–π —Å–∫—Ä–∏–ø—Ç –¥–ª—è –º–µ–Ω–µ–¥–∂–µ—Ä–∞ –∏—Å—Ç–æ—Ä–∏–∏:

1. **–î–æ–±–∞–≤–ª–µ–Ω

---

## üõ†Ô∏è –í—ã–ø–æ–ª–Ω–µ–Ω–Ω—ã–µ –≤—ã–∑–æ–≤—ã –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–≤

1. ‚úÖ **read_file**
   - –ê—Ä–≥—É–º–µ–Ω—Ç—ã: `file_path=scripts/test_history_manager.py`

2. ‚úÖ **read_code_chunk**
   - –ê—Ä–≥—É–º–µ–Ω—Ç—ã: `file_path=app/history/compressor.py, chunk_name=compress_history_if_needed`

3. ‚úÖ **read_code_chunk**
   - –ê—Ä–≥—É–º–µ–Ω—Ç—ã: `file_path=app/history/compressor.py, chunk_name=prune_irrelevant_context`

---

*–û—Ç—á–µ—Ç —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏: 2025-12-15T01:15:28.524545*