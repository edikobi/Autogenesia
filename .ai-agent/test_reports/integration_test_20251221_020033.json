{
  "metadata": {
    "timestamp": "2025-12-21T02:00:33.864944",
    "project_dir": "C:\\Users\\Admin\\AI_Assistant_Pro",
    "user_query": "Я хочу внедрить еще одну модель ИИ для Оркестратора (просто для выбора пользователя, как Deepseek V3.2 рассуждающий), а именно Gemini 3.0 pro. Проанализируй файлы проекта, особенно settings.py, orchestrator.py, api_client.py и укажи, учитывая особенность этой модели при работе с инструментами (надо парсить и возвращать Thought Signatures назад), то как аккуратно внедрить эту модель, чтобы не испортить работу остальных моделей. Важно (!) ищи в Интернете официальную документацию именно на модель Gemini 3.0 pro! После анализа, напиши код решения и укажи, куда его вставить.",
    "duration_seconds": 498.6190981864929,
    "models_used": {
      "orchestrator": "DeepSeek V3.2 Reasoning",
      "code_generator": "deepseek-chat"
    }
  },
  "orchestrator": {
    "analysis": "После анализа проекта и веб-поиска по документации Gemini 3.0 Pro, я выявил следующее:\n\n**Текущее состояние**: Модель Gemini 3.0 Pro уже частично настроена в проекте:\n1. В `config/settings.py` есть конфигурация для `MODEL_GEMINI_3_PRO = \"google/gemini-3-pro-preview\"`\n2. В `MODEL_CONFIGS` есть настройки с `extra_params: {\"reasoning_effort\": \"high\"}`\n3. Модель уже добавлена в список доступных моделей оркестратора\n\n**Критическая особенность Gemini 3.0 Pro**: Thought Signatures (подписи мыслей)\n- Это зашифрованные представления внутреннего процесса рассуждения модели\n- **Обязательны** для работы с инструментами (tool calls)\n- Без них получается ошибка 400: \"Function call is missing a thought_signature\"\n- Должны сохраняться и передаваться обратно в следующих запросах\n\n**ROOT CAUSE**: Текущая реализация `LLMClient` обрабатывает только `reasoning_content` для DeepSeek, но игнорирует `thought_signature` для Gemini 3.0 Pro. При использовании инструментов с Gemini, система не сохраняет и не передает thought signatures обратно, что приводит к разрыву цепочки рассуждений и ошибке 400.\n\n**Проблема в архитектуре**:\n1. `LLMClient._parse_response()` извлекает только `reasoning_content` для DeepSeek\n2. Система не сохраняет `thought_signature` из ответов Gemini\n3. При следующем запросе подписи не передаются, ломая цепочку рассуждений\n\n**Решение**: Нужно модифицировать три ключевых файла для поддержки Thought Signatures:\n1. `app/llm/api_client.py` - извлекать и сохранять thought signatures\n2. `app/tools/tool_executor.py` - обрабатывать thought signatures при парсинге вызовов инструментов\n3. `app/agents/orchestrator.py` - передавать thought signatures в истории сообщений",
    "instruction": "**SCOPE:** Multiple files\n\n**Task:** Добавить поддержку Thought Signatures для Gemini 3.0 Pro в цепочке обработки инструментов\n\n---"
  },
  "code_generator": {
    "code_blocks": [
      {
        "filepath": "app/agents/thought_signature.py",
        "language": "python",
        "code": "\"\"\"\nThought Signature support for Gemini 3.0 Pro in tool processing chain.\n\nThis module provides functionality to generate and validate thought signatures\nfor Gemini 3.0 Pro API responses when using tools/function calling.\n\"\"\"\n\nimport hashlib\nimport json\nimport time\nfrom typing import Any, Dict, Optional, Union\nfrom dataclasses import dataclass, asdict\n\n\n@dataclass\nclass ThoughtSignature:\n    \"\"\"Represents a thought signature for Gemini tool processing.\"\"\"\n    \n    model: str\n    timestamp: float\n    tool_calls_hash: str\n    reasoning_hash: Optional[str] = None\n    signature: Optional[str] = None\n    \n    def to_dict(self) -> Dict[str, Any]:\n        \"\"\"Convert to dictionary for serialization.\"\"\"\n        return asdict(self)\n    \n    @classmethod\n    def from_dict(cls, data: Dict[str, Any]) -> 'ThoughtSignature':\n        \"\"\"Create ThoughtSignature from dictionary.\"\"\"\n        return cls(**data)\n\n\nclass ThoughtSignatureGenerator:\n    \"\"\"Generates thought signatures for Gemini 3.0 Pro tool calls.\"\"\"\n    \n    def __init__(self, model: str = \"gemini-3.0-pro\"):\n        \"\"\"\n        Initialize the thought signature generator.\n        \n        Args:\n            model: The Gemini model name (default: \"gemini-3.0-pro\")\n        \"\"\"\n        self.model = model\n        self._secret_salt = \"gemini_thought_signature_v1\"\n    \n    def generate_tool_calls_hash(self, tool_calls: list) -> str:\n        \"\"\"\n        Generate hash for tool calls to ensure integrity.\n        \n        Args:\n            tool_calls: List of tool call dictionaries\n            \n        Returns:\n            SHA-256 hash of the tool calls\n        \"\"\"\n        # Normalize tool calls for consistent hashing\n        normalized = []\n        for call in tool_calls:\n            if isinstance(call, dict):\n                # Sort keys for consistent ordering\n                normalized_call = {}\n                for key in sorted(call.keys()):\n                    value = call[key]\n                    if isinstance(value, (dict, list)):\n                        # Recursively normalize nested structures\n                        normalized_call[key] = json.dumps(value, sort_keys=True)\n                    else:\n                        normalized_call[key] = str(value)\n                normalized.append(normalized_call)\n        \n        # Create deterministic string representation\n        tool_calls_str = json.dumps(normalized, sort_keys=True)\n        \n        # Generate hash\n        return hashlib.sha256(tool_calls_str.encode()).hexdigest()\n    \n    def generate_reasoning_hash(self, reasoning_text: str) -> str:\n        \"\"\"\n        Generate hash for reasoning text.\n        \n        Args:\n            reasoning_text: The model's reasoning/thought process text\n            \n        Returns:\n            SHA-256 hash of the reasoning text\n        \"\"\"\n        normalized_text = reasoning_text.strip()\n        return hashlib.sha256(normalized_text.encode()).hexdigest()\n    \n    def create_signature(\n        self,\n        tool_calls: list,\n        reasoning_text: Optional[str] = None,\n        timestamp: Optional[float] = None\n    ) -> ThoughtSignature:\n        \"\"\"\n        Create a complete thought signature.\n        \n        Args:\n            tool_calls: List of tool call dictionaries\n            reasoning_text: Optional reasoning text from the model\n            timestamp: Optional timestamp (defaults to current time)\n            \n        Returns:\n            ThoughtSignature object\n        \"\"\"\n        if timestamp is None:\n            timestamp = time.time()\n        \n        # Generate hashes\n        tool_calls_hash = self.generate_tool_calls_hash(tool_calls)\n        reasoning_hash = None\n        if reasoning_text:\n            reasoning_hash = self.generate_reasoning_hash(reasoning_text)\n        \n        # Create combined hash for final signature\n        combined_data = f\"{self.model}|{timestamp}|{tool_calls_hash}\"\n        if reasoning_hash:\n            combined_data += f\"|{reasoning_hash}\"\n        combined_data += f\"|{self._secret_salt}\"\n        \n        final_signature = hashlib.sha256(combined_data.encode()).hexdigest()\n        \n        return ThoughtSignature(\n            model=self.model,\n            timestamp=timestamp,\n            tool_calls_hash=tool_calls_hash,\n            reasoning_hash=reasoning_hash,\n            signature=final_signature\n        )\n    \n    def validate_signature(\n        self,\n        signature_obj: ThoughtSignature,\n        tool_calls: list,\n        reasoning_text: Optional[str] = None,\n        tolerance_seconds: int = 300\n    ) -> bool:\n        \"\"\"\n        Validate a thought signature.\n        \n        Args:\n            signature_obj: The ThoughtSignature to validate\n            tool_calls: Original tool calls to verify against\n            reasoning_text: Original reasoning text to verify against\n            tolerance_seconds: Time tolerance in seconds (default: 5 minutes)\n            \n        Returns:\n            True if signature is valid, False otherwise\n        \"\"\"\n        # Check timestamp freshness\n        current_time = time.time()\n        if abs(current_time - signature_obj.timestamp) > tolerance_seconds:\n            return False\n        \n        # Verify tool calls hash\n        expected_tool_hash = self.generate_tool_calls_hash(tool_calls)\n        if expected_tool_hash != signature_obj.tool_calls_hash:\n            return False\n        \n        # Verify reasoning hash if present\n        if signature_obj.reasoning_hash:\n            if not reasoning_text:\n                return False\n            expected_reasoning_hash = self.generate_reasoning_hash(reasoning_text)\n            if expected_reasoning_hash != signature_obj.reasoning_hash:\n                return False\n        \n        # Recreate signature to verify\n        expected_signature = self.create_signature(\n            tool_calls=tool_calls,\n            reasoning_text=reasoning_text,\n            timestamp=signature_obj.timestamp\n        )\n        \n        return expected_signature.signature == signature_obj.signature\n\n\nclass GeminiToolProcessor:\n    \"\"\"\n    Main processor for Gemini 3.0 Pro tool calls with thought signature support.\n    \"\"\"\n    \n    def __init__(self, model: str = \"gemini-3.0-pro\"):\n        \"\"\"\n        Initialize the Gemini tool processor.\n        \n        Args:\n            model: Gemini model name\n        \"\"\"\n        self.model = model\n        self.signature_generator = ThoughtSignatureGenerator(model)\n    \n    def process_with_signature(\n        self,\n        gemini_response: Dict[str, Any],\n        include_reasoning: bool = True\n    ) -> Dict[str, Any]:\n        \"\"\"\n        Process Gemini response and add thought signature.\n        \n        Args:\n            gemini_response: Raw response from Gemini API\n            include_reasoning: Whether to include reasoning in signature\n            \n        Returns:\n            Processed response with thought signature\n        \"\"\"\n        # Extract tool calls from Gemini response\n        tool_calls = self._extract_tool_calls(gemini_response)\n        \n        # Extract reasoning if available and requested\n        reasoning_text = None\n        if include_reasoning:\n            reasoning_text = self._extract_reasoning(gemini_response)\n        \n        # Generate thought signature\n        signature = self.signature_generator.create_signature(\n            tool_calls=tool_calls,\n            reasoning_text=reasoning_text\n        )\n        \n        # Return enhanced response\n        return {\n            \"original_response\": gemini_response,\n            \"tool_calls\": tool_calls,\n            \"reasoning\": reasoning_text,\n            \"thought_signature\": signature.to_dict(),\n            \"metadata\": {\n                \"model\": self.model,\n                \"processed_at\": time.time(),\n                \"signature_valid\": True\n            }\n        }\n    \n    def validate_processed_response(\n        self,\n        processed_response: Dict[str, Any]\n    ) -> bool:\n        \"\"\"\n        Validate a previously processed response.\n        \n        Args:\n            processed_response: Response processed by process_with_signature\n            \n        Returns:\n            True if signature is valid, False otherwise\n        \"\"\"\n        if \"thought_signature\" not in processed_response:\n            return False\n        \n        if \"tool_calls\" not in processed_response:\n            return False\n        \n        # Reconstruct signature object\n        signature_data = processed_response[\"thought_signature\"]\n        signature_obj = ThoughtSignature.from_dict(signature_data)\n        \n        # Get original data\n        tool_calls = processed_response[\"tool_calls\"]\n        reasoning_text = processed_response.get(\"reasoning\")\n        \n        # Validate\n        return self.signature_generator.validate_signature(\n            signature_obj=signature_obj,\n            tool_calls=tool_calls,\n            reasoning_text=reasoning_text\n        )\n    \n    def _extract_tool_calls(self, gemini_response: Dict[str, Any]) -> list:\n        \"\"\"\n        Extract tool calls from Gemini response.\n        \n        Args:\n            gemini_response: Raw Gemini API response\n            \n        Returns:\n            List of tool call dictionaries\n        \"\"\"\n        # This is a simplified extraction - adjust based on actual Gemini API response format\n        tool_calls = []\n        \n        # Check for function calling format\n        if \"candidates\" in gemini_response:\n            for candidate in gemini_response[\"candidates\"]:\n                if \"content\" in candidate and \"parts\" in candidate[\"content\"]:\n                    for part in candidate[\"content\"][\"parts\"]:\n                        if \"functionCall\" in part:\n                            tool_calls.append({\n                                \"function\": part[\"functionCall\"][\"name\"],\n                                \"args\": part[\"functionCall\"].get(\"args\", {})\n                            })\n        \n        return tool_calls\n    \n    def _extract_reasoning(self, gemini_response: Dict[str, Any]) -> Optional[str]:\n        \"\"\"\n        Extract reasoning text from Gemini response.\n        \n        Args:\n            gemini_response: Raw Gemini API response\n            \n        Returns:\n            Reasoning text or None if not available\n        \"\"\"\n        # This is a simplified extraction - adjust based on actual Gemini API response format\n        reasoning_parts = []\n        \n        if \"candidates\" in gemini_response:\n            for candidate in gemini_response[\"candidates\"]:\n                if \"content\" in candidate and \"parts\" in candidate[\"content\"]:\n                    for part in candidate[\"content\"][\"parts\"]:\n                        if isinstance(part, dict) and \"text\" in part:\n                            text = part[\"text\"]\n                            # Simple heuristic: look for reasoning indicators\n                            if any(indicator in text.lower() for indicator in \n                                   [\"reasoning:\", \"thought:\", \"thinking:\", \"step\"]):\n                                reasoning_parts.append(text)\n        \n        return \" \".join(reasoning_parts) if reasoning_parts else None",
        "context": null
      },
      {
        "filepath": "app/agents/__init__.py",
        "language": "python",
        "code": "\"\"\"\nAgents package for AI tool processing with thought signatures.\n\"\"\"\n\nfrom app.agents.thought_signature import (\n    ThoughtSignature,\n    ThoughtSignatureGenerator,\n    GeminiToolProcessor\n)\n\n__all__ = [\n    \"ThoughtSignature\",\n    \"ThoughtSignatureGenerator\",\n    \"GeminiToolProcessor\"\n]",
        "context": null
      }
    ],
    "explanation": "```\n# filepath: tests/test_thought_signature.py\n\"\"\"\nTests for Thought Signature functionality.\n\"\"\"\n\nimport pytest\nimport time\nfrom app.agents.thought_signature import (\n    ThoughtSignature,\n    ThoughtSignatureGenerator,\n    GeminiToolProcessor\n)\n\n\nclass TestThoughtSignature:\n    \"\"\"Test ThoughtSignature dataclass.\"\"\"\n    \n    def test_creation(self):\n        \"\"\"Test creating a ThoughtSignature.\"\"\"\n        signature = ThoughtSignature(\n            model=\"gemini-3.0-pro\",\n            timestamp=1234567890.0,\n            tool_calls_hash=\"abc123\",\n            reasoning_hash=\"def456\",\n            signature=\"final_sig\"\n        )\n        \n        assert signature.model == \"gemini-3.0-pro\"\n        assert signature.timestamp == 1234567890.0\n        assert signature.tool_calls_hash == \"abc123\"\n        assert signature.reasoning_hash == \"def456\"\n        assert signature.signature == \"final_sig\"\n    \n    def test_to_from_dict(self):\n        \"\"\"Test dictionary serialization/deserialization.\"\"\"\n        original = ThoughtSignature(\n            model=\"gemini-3.0-pro\",\n            timestamp=1234567890.0,\n            tool_calls_hash=\"abc123\",\n            reasoning_hash=\"def456\",\n            signature=\"final_sig\"\n        )\n        \n        as_dict = original.to_dict()\n        restored = ThoughtSignature.from_dict(as_dict)\n        \n        assert original == restored\n\n\nclass TestThoughtSignatureGenerator:\n    \"\"\"Test ThoughtSignatureGenerator.\"\"\"\n    \n    def setup_method(self):\n        \"\"\"Setup test fixture.\"\"\"\n        self.generator = ThoughtSignatureGenerator(model=\"gemini-3.0-pro\")\n    \n    def test_generate_tool_calls_hash(self):\n        \"\"\"Test tool calls hash generation.\"\"\"\n        tool_calls = [\n            {\"function\": \"search\", \"args\": {\"query\": \"test\"}},\n            {\"function\": \"calculate\", \"args\": {\"x\": 1, \"y\": 2}}\n        ]\n        \n        hash1 = self.generator.generate_tool_calls_hash(tool_calls)\n        hash2 = self.generator.generate_tool_calls_hash(tool_calls)\n        \n        # Same input should produce same hash\n        assert hash1 == hash2\n        \n        # Different input should produce different hash\n        different_calls = [{\"function\": \"search\", \"args\": {\"query\": \"different\"}}]\n        hash3 = self.generator.generate_tool_calls_hash(different_calls)\n        assert hash1 != hash3\n    \n    def test_generate_reasoning_hash(self):\n        \"\"\"Test reasoning hash generation.\"\"\"\n        reasoning = \"I need to search for information about AI.\"\n        \n        hash1 = self.generator.generate_reasoning_hash(reasoning)\n        hash2 = self.generator.generate_reasoning_hash(reasoning)\n        \n        assert hash1 == hash2\n        \n        # Different reasoning should produce different hash\n        different_reasoning = \"Different reasoning text.\"\n        hash3 = self.generator.generate_reasoning_hash(different_reasoning)\n        assert hash1 != hash3\n    \n    def test_create_signature(self):\n        \"\"\"Test complete signature creation.\"\"\"\n        tool_calls = [{\"function\": \"search\", \"args\": {\"query\": \"test\"}}]\n        reasoning = \"Test reasoning\"\n        \n        signature = self.generator.create_signature(\n            tool_calls=tool_calls,\n            reasoning_text=reasoning\n        )\n        \n        assert signature.model == \"gemini-3.0-pro\"\n        assert signature.timestamp <= time.time()\n        assert signature.tool_calls_hash is not None\n        assert signature.reasoning_hash is not None\n        assert signature.signature is not None\n    \n    def test_validate_signature(self):\n        \"\"\"Test signature validation.\"\"\"\n        tool_calls = [{\"function\": \"search\", \"args\": {\"query\": \"test\"}}]\n        reasoning = \"Test reasoning\"\n        \n        signature = self.generator.create_signature(\n            tool_calls=tool_calls,\n            reasoning_text=reasoning\n        )\n        \n        # Valid signature should pass\n        assert self.generator.validate_signature(\n            signature_obj=signature,\n            tool_calls=tool_calls,\n            reasoning_text=reasoning\n        )\n        \n        # Different tool calls should fail\n        different_calls = [{\"function\": \"search\", \"args\": {\"query\": \"different\"}}]\n        assert not self.generator.validate_signature(\n            signature_obj=signature,\n            tool_calls=different_calls,\n            reasoning_text=reasoning\n        )\n        \n        # Different reasoning should fail\n        different_reasoning = \"Different reasoning\"\n        assert not self.generator.validate_signature(\n            signature_obj=signature,\n            tool_calls=tool_calls,\n            reasoning_text=different_reasoning\n        )\n    \n    def test_validate_signature_timestamp(self):\n        \"\"\"Test timestamp validation with tolerance.\"\"\"\n        tool_calls = [{\"function\": \"search\", \"args\": {\"query\": \"test\"}}]\n        \n        # Create signature with old timestamp\n        old_timestamp = time.time() - 400  # More than 5 minutes old\n        signature = self.generator.create_signature(\n            tool_calls=tool_calls,\n            reasoning_text=None,\n            timestamp=old_timestamp\n        )\n        \n        # Should fail with default tolerance (300 seconds)\n        assert not self.generator.validate_signature(\n            signature_obj=signature,\n            tool_calls=tool_calls,\n            reasoning_text=None\n        )\n        \n        # Should pass with larger tolerance\n        assert self.generator.validate_signature(\n            signature_obj=signature,\n            tool_calls=tool_calls,\n            reasoning_text=None,\n            tolerance_seconds=500\n        )\n\n\nclass TestGeminiToolProcessor:\n    \"\"\"Test GeminiToolProcessor.\"\"\"\n    \n    def setup_method(self):\n        \"\"\"Setup test fixture.\"\"\"\n        self.processor = GeminiToolProcessor(model=\"gemini-3.0-pro\")\n    \n    def test_process_with_signature(self):\n        \"\"\"Test processing Gemini response with signature.\"\"\"\n        # Mock Gemini response\n        gemini_response = {\n            \"candidates\": [{\n                \"content\": {\n                    \"parts\": [\n                        {\"text\": \"Reasoning: I need to search for AI information.\"},\n                        {\"functionCall\": {\n                            \"name\": \"search\",\n                            \"args\": {\"query\": \"artificial intelligence\"}\n                        }}\n                    ]\n                }\n            }]\n        }\n        \n        processed = self.processor.process_with_signature(\n            gemini_response=gemini_response,\n            include_reasoning=True\n        )\n        \n        assert \"original_response\" in processed\n        assert \"tool_calls\" in processed\n        assert \"reasoning\" in processed\n        assert \"thought_signature\" in processed\n        assert \"metadata\" in processed\n        \n        # Should have extracted tool calls\n        assert len(processed[\"tool_calls\"]) > 0\n        \n        # Should have extracted reasoning\n        assert processed[\"reasoning\"] is not None\n        \n        # Signature should be valid\n        assert processed[\"metadata\"][\"signature_valid\"] is True\n    \n    def test_validate_processed_response(self):\n        \"\"\"Test validation of processed response.\"\"\"\n        # Create a processed response\n        gemini_response = {\n            \"candidates\": [{\n                \"content\": {\n                    \"parts\": [\n                        {\"functionCall\": {\n                            \"name\": \"calculate\",\n                            \"args\": {\"x\": 5, \"y\": 3}\n                        }}\n                    ]\n                }\n            }]\n        }\n        \n        processed = self.processor.process_with_signature(\n            gemini_response=gemini_response,\n            include_reasoning=False\n        )\n        \n        # Should validate successfully\n        assert self.processor.validate_processed_response(processed)\n        \n        # Tampered response should fail\n        tampered = processed.copy()\n        tampered[\"tool_calls\"][0][\"args\"][\"x\"] = 10  # Change argument\n        \n        assert not self.processor.validate_processed_response(tampered)\n    \n    def test_extract_tool_calls(self):\n        \"\"\"Test tool call extraction.\"\"\"",
    "frontend_json": {
      "success": true,
      "code_blocks": [
        {
          "code": "\"\"\"\nThought Signature support for Gemini 3.0 Pro in tool processing chain.\n\nThis module provides functionality to generate and validate thought signatures\nfor Gemini 3.0 Pro API responses when using tools/function calling.\n\"\"\"\n\nimport hashlib\nimport json\nimport time\nfrom typing import Any, Dict, Optional, Union\nfrom dataclasses import dataclass, asdict\n\n\n@dataclass\nclass ThoughtSignature:\n    \"\"\"Represents a thought signature for Gemini tool processing.\"\"\"\n    \n    model: str\n    timestamp: float\n    tool_calls_hash: str\n    reasoning_hash: Optional[str] = None\n    signature: Optional[str] = None\n    \n    def to_dict(self) -> Dict[str, Any]:\n        \"\"\"Convert to dictionary for serialization.\"\"\"\n        return asdict(self)\n    \n    @classmethod\n    def from_dict(cls, data: Dict[str, Any]) -> 'ThoughtSignature':\n        \"\"\"Create ThoughtSignature from dictionary.\"\"\"\n        return cls(**data)\n\n\nclass ThoughtSignatureGenerator:\n    \"\"\"Generates thought signatures for Gemini 3.0 Pro tool calls.\"\"\"\n    \n    def __init__(self, model: str = \"gemini-3.0-pro\"):\n        \"\"\"\n        Initialize the thought signature generator.\n        \n        Args:\n            model: The Gemini model name (default: \"gemini-3.0-pro\")\n        \"\"\"\n        self.model = model\n        self._secret_salt = \"gemini_thought_signature_v1\"\n    \n    def generate_tool_calls_hash(self, tool_calls: list) -> str:\n        \"\"\"\n        Generate hash for tool calls to ensure integrity.\n        \n        Args:\n            tool_calls: List of tool call dictionaries\n            \n        Returns:\n            SHA-256 hash of the tool calls\n        \"\"\"\n        # Normalize tool calls for consistent hashing\n        normalized = []\n        for call in tool_calls:\n            if isinstance(call, dict):\n                # Sort keys for consistent ordering\n                normalized_call = {}\n                for key in sorted(call.keys()):\n                    value = call[key]\n                    if isinstance(value, (dict, list)):\n                        # Recursively normalize nested structures\n                        normalized_call[key] = json.dumps(value, sort_keys=True)\n                    else:\n                        normalized_call[key] = str(value)\n                normalized.append(normalized_call)\n        \n        # Create deterministic string representation\n        tool_calls_str = json.dumps(normalized, sort_keys=True)\n        \n        # Generate hash\n        return hashlib.sha256(tool_calls_str.encode()).hexdigest()\n    \n    def generate_reasoning_hash(self, reasoning_text: str) -> str:\n        \"\"\"\n        Generate hash for reasoning text.\n        \n        Args:\n            reasoning_text: The model's reasoning/thought process text\n            \n        Returns:\n            SHA-256 hash of the reasoning text\n        \"\"\"\n        normalized_text = reasoning_text.strip()\n        return hashlib.sha256(normalized_text.encode()).hexdigest()\n    \n    def create_signature(\n        self,\n        tool_calls: list,\n        reasoning_text: Optional[str] = None,\n        timestamp: Optional[float] = None\n    ) -> ThoughtSignature:\n        \"\"\"\n        Create a complete thought signature.\n        \n        Args:\n            tool_calls: List of tool call dictionaries\n            reasoning_text: Optional reasoning text from the model\n            timestamp: Optional timestamp (defaults to current time)\n            \n        Returns:\n            ThoughtSignature object\n        \"\"\"\n        if timestamp is None:\n            timestamp = time.time()\n        \n        # Generate hashes\n        tool_calls_hash = self.generate_tool_calls_hash(tool_calls)\n        reasoning_hash = None\n        if reasoning_text:\n            reasoning_hash = self.generate_reasoning_hash(reasoning_text)\n        \n        # Create combined hash for final signature\n        combined_data = f\"{self.model}|{timestamp}|{tool_calls_hash}\"\n        if reasoning_hash:\n            combined_data += f\"|{reasoning_hash}\"\n        combined_data += f\"|{self._secret_salt}\"\n        \n        final_signature = hashlib.sha256(combined_data.encode()).hexdigest()\n        \n        return ThoughtSignature(\n            model=self.model,\n            timestamp=timestamp,\n            tool_calls_hash=tool_calls_hash,\n            reasoning_hash=reasoning_hash,\n            signature=final_signature\n        )\n    \n    def validate_signature(\n        self,\n        signature_obj: ThoughtSignature,\n        tool_calls: list,\n        reasoning_text: Optional[str] = None,\n        tolerance_seconds: int = 300\n    ) -> bool:\n        \"\"\"\n        Validate a thought signature.\n        \n        Args:\n            signature_obj: The ThoughtSignature to validate\n            tool_calls: Original tool calls to verify against\n            reasoning_text: Original reasoning text to verify against\n            tolerance_seconds: Time tolerance in seconds (default: 5 minutes)\n            \n        Returns:\n            True if signature is valid, False otherwise\n        \"\"\"\n        # Check timestamp freshness\n        current_time = time.time()\n        if abs(current_time - signature_obj.timestamp) > tolerance_seconds:\n            return False\n        \n        # Verify tool calls hash\n        expected_tool_hash = self.generate_tool_calls_hash(tool_calls)\n        if expected_tool_hash != signature_obj.tool_calls_hash:\n            return False\n        \n        # Verify reasoning hash if present\n        if signature_obj.reasoning_hash:\n            if not reasoning_text:\n                return False\n            expected_reasoning_hash = self.generate_reasoning_hash(reasoning_text)\n            if expected_reasoning_hash != signature_obj.reasoning_hash:\n                return False\n        \n        # Recreate signature to verify\n        expected_signature = self.create_signature(\n            tool_calls=tool_calls,\n            reasoning_text=reasoning_text,\n            timestamp=signature_obj.timestamp\n        )\n        \n        return expected_signature.signature == signature_obj.signature\n\n\nclass GeminiToolProcessor:\n    \"\"\"\n    Main processor for Gemini 3.0 Pro tool calls with thought signature support.\n    \"\"\"\n    \n    def __init__(self, model: str = \"gemini-3.0-pro\"):\n        \"\"\"\n        Initialize the Gemini tool processor.\n        \n        Args:\n            model: Gemini model name\n        \"\"\"\n        self.model = model\n        self.signature_generator = ThoughtSignatureGenerator(model)\n    \n    def process_with_signature(\n        self,\n        gemini_response: Dict[str, Any],\n        include_reasoning: bool = True\n    ) -> Dict[str, Any]:\n        \"\"\"\n        Process Gemini response and add thought signature.\n        \n        Args:\n            gemini_response: Raw response from Gemini API\n            include_reasoning: Whether to include reasoning in signature\n            \n        Returns:\n            Processed response with thought signature\n        \"\"\"\n        # Extract tool calls from Gemini response\n        tool_calls = self._extract_tool_calls(gemini_response)\n        \n        # Extract reasoning if available and requested\n        reasoning_text = None\n        if include_reasoning:\n            reasoning_text = self._extract_reasoning(gemini_response)\n        \n        # Generate thought signature\n        signature = self.signature_generator.create_signature(\n            tool_calls=tool_calls,\n            reasoning_text=reasoning_text\n        )\n        \n        # Return enhanced response\n        return {\n            \"original_response\": gemini_response,\n            \"tool_calls\": tool_calls,\n            \"reasoning\": reasoning_text,\n            \"thought_signature\": signature.to_dict(),\n            \"metadata\": {\n                \"model\": self.model,\n                \"processed_at\": time.time(),\n                \"signature_valid\": True\n            }\n        }\n    \n    def validate_processed_response(\n        self,\n        processed_response: Dict[str, Any]\n    ) -> bool:\n        \"\"\"\n        Validate a previously processed response.\n        \n        Args:\n            processed_response: Response processed by process_with_signature\n            \n        Returns:\n            True if signature is valid, False otherwise\n        \"\"\"\n        if \"thought_signature\" not in processed_response:\n            return False\n        \n        if \"tool_calls\" not in processed_response:\n            return False\n        \n        # Reconstruct signature object\n        signature_data = processed_response[\"thought_signature\"]\n        signature_obj = ThoughtSignature.from_dict(signature_data)\n        \n        # Get original data\n        tool_calls = processed_response[\"tool_calls\"]\n        reasoning_text = processed_response.get(\"reasoning\")\n        \n        # Validate\n        return self.signature_generator.validate_signature(\n            signature_obj=signature_obj,\n            tool_calls=tool_calls,\n            reasoning_text=reasoning_text\n        )\n    \n    def _extract_tool_calls(self, gemini_response: Dict[str, Any]) -> list:\n        \"\"\"\n        Extract tool calls from Gemini response.\n        \n        Args:\n            gemini_response: Raw Gemini API response\n            \n        Returns:\n            List of tool call dictionaries\n        \"\"\"\n        # This is a simplified extraction - adjust based on actual Gemini API response format\n        tool_calls = []\n        \n        # Check for function calling format\n        if \"candidates\" in gemini_response:\n            for candidate in gemini_response[\"candidates\"]:\n                if \"content\" in candidate and \"parts\" in candidate[\"content\"]:\n                    for part in candidate[\"content\"][\"parts\"]:\n                        if \"functionCall\" in part:\n                            tool_calls.append({\n                                \"function\": part[\"functionCall\"][\"name\"],\n                                \"args\": part[\"functionCall\"].get(\"args\", {})\n                            })\n        \n        return tool_calls\n    \n    def _extract_reasoning(self, gemini_response: Dict[str, Any]) -> Optional[str]:\n        \"\"\"\n        Extract reasoning text from Gemini response.\n        \n        Args:\n            gemini_response: Raw Gemini API response\n            \n        Returns:\n            Reasoning text or None if not available\n        \"\"\"\n        # This is a simplified extraction - adjust based on actual Gemini API response format\n        reasoning_parts = []\n        \n        if \"candidates\" in gemini_response:\n            for candidate in gemini_response[\"candidates\"]:\n                if \"content\" in candidate and \"parts\" in candidate[\"content\"]:\n                    for part in candidate[\"content\"][\"parts\"]:\n                        if isinstance(part, dict) and \"text\" in part:\n                            text = part[\"text\"]\n                            # Simple heuristic: look for reasoning indicators\n                            if any(indicator in text.lower() for indicator in \n                                   [\"reasoning:\", \"thought:\", \"thinking:\", \"step\"]):\n                                reasoning_parts.append(text)\n        \n        return \" \".join(reasoning_parts) if reasoning_parts else None",
          "filepath": "app/agents/thought_signature.py",
          "language": "python",
          "context": null
        },
        {
          "code": "\"\"\"\nAgents package for AI tool processing with thought signatures.\n\"\"\"\n\nfrom app.agents.thought_signature import (\n    ThoughtSignature,\n    ThoughtSignatureGenerator,\n    GeminiToolProcessor\n)\n\n__all__ = [\n    \"ThoughtSignature\",\n    \"ThoughtSignatureGenerator\",\n    \"GeminiToolProcessor\"\n]",
          "filepath": "app/agents/__init__.py",
          "language": "python",
          "context": null
        }
      ],
      "combined_code": "\n\n# ==================================================# filepath: app/agents/thought_signature.py\n\n\"\"\"\nThought Signature support for Gemini 3.0 Pro in tool processing chain.\n\nThis module provides functionality to generate and validate thought signatures\nfor Gemini 3.0 Pro API responses when using tools/function calling.\n\"\"\"\n\nimport hashlib\nimport json\nimport time\nfrom typing import Any, Dict, Optional, Union\nfrom dataclasses import dataclass, asdict\n\n\n@dataclass\nclass ThoughtSignature:\n    \"\"\"Represents a thought signature for Gemini tool processing.\"\"\"\n    \n    model: str\n    timestamp: float\n    tool_calls_hash: str\n    reasoning_hash: Optional[str] = None\n    signature: Optional[str] = None\n    \n    def to_dict(self) -> Dict[str, Any]:\n        \"\"\"Convert to dictionary for serialization.\"\"\"\n        return asdict(self)\n    \n    @classmethod\n    def from_dict(cls, data: Dict[str, Any]) -> 'ThoughtSignature':\n        \"\"\"Create ThoughtSignature from dictionary.\"\"\"\n        return cls(**data)\n\n\nclass ThoughtSignatureGenerator:\n    \"\"\"Generates thought signatures for Gemini 3.0 Pro tool calls.\"\"\"\n    \n    def __init__(self, model: str = \"gemini-3.0-pro\"):\n        \"\"\"\n        Initialize the thought signature generator.\n        \n        Args:\n            model: The Gemini model name (default: \"gemini-3.0-pro\")\n        \"\"\"\n        self.model = model\n        self._secret_salt = \"gemini_thought_signature_v1\"\n    \n    def generate_tool_calls_hash(self, tool_calls: list) -> str:\n        \"\"\"\n        Generate hash for tool calls to ensure integrity.\n        \n        Args:\n            tool_calls: List of tool call dictionaries\n            \n        Returns:\n            SHA-256 hash of the tool calls\n        \"\"\"\n        # Normalize tool calls for consistent hashing\n        normalized = []\n        for call in tool_calls:\n            if isinstance(call, dict):\n                # Sort keys for consistent ordering\n                normalized_call = {}\n                for key in sorted(call.keys()):\n                    value = call[key]\n                    if isinstance(value, (dict, list)):\n                        # Recursively normalize nested structures\n                        normalized_call[key] = json.dumps(value, sort_keys=True)\n                    else:\n                        normalized_call[key] = str(value)\n                normalized.append(normalized_call)\n        \n        # Create deterministic string representation\n        tool_calls_str = json.dumps(normalized, sort_keys=True)\n        \n        # Generate hash\n        return hashlib.sha256(tool_calls_str.encode()).hexdigest()\n    \n    def generate_reasoning_hash(self, reasoning_text: str) -> str:\n        \"\"\"\n        Generate hash for reasoning text.\n        \n        Args:\n            reasoning_text: The model's reasoning/thought process text\n            \n        Returns:\n            SHA-256 hash of the reasoning text\n        \"\"\"\n        normalized_text = reasoning_text.strip()\n        return hashlib.sha256(normalized_text.encode()).hexdigest()\n    \n    def create_signature(\n        self,\n        tool_calls: list,\n        reasoning_text: Optional[str] = None,\n        timestamp: Optional[float] = None\n    ) -> ThoughtSignature:\n        \"\"\"\n        Create a complete thought signature.\n        \n        Args:\n            tool_calls: List of tool call dictionaries\n            reasoning_text: Optional reasoning text from the model\n            timestamp: Optional timestamp (defaults to current time)\n            \n        Returns:\n            ThoughtSignature object\n        \"\"\"\n        if timestamp is None:\n            timestamp = time.time()\n        \n        # Generate hashes\n        tool_calls_hash = self.generate_tool_calls_hash(tool_calls)\n        reasoning_hash = None\n        if reasoning_text:\n            reasoning_hash = self.generate_reasoning_hash(reasoning_text)\n        \n        # Create combined hash for final signature\n        combined_data = f\"{self.model}|{timestamp}|{tool_calls_hash}\"\n        if reasoning_hash:\n            combined_data += f\"|{reasoning_hash}\"\n        combined_data += f\"|{self._secret_salt}\"\n        \n        final_signature = hashlib.sha256(combined_data.encode()).hexdigest()\n        \n        return ThoughtSignature(\n            model=self.model,\n            timestamp=timestamp,\n            tool_calls_hash=tool_calls_hash,\n            reasoning_hash=reasoning_hash,\n            signature=final_signature\n        )\n    \n    def validate_signature(\n        self,\n        signature_obj: ThoughtSignature,\n        tool_calls: list,\n        reasoning_text: Optional[str] = None,\n        tolerance_seconds: int = 300\n    ) -> bool:\n        \"\"\"\n        Validate a thought signature.\n        \n        Args:\n            signature_obj: The ThoughtSignature to validate\n            tool_calls: Original tool calls to verify against\n            reasoning_text: Original reasoning text to verify against\n            tolerance_seconds: Time tolerance in seconds (default: 5 minutes)\n            \n        Returns:\n            True if signature is valid, False otherwise\n        \"\"\"\n        # Check timestamp freshness\n        current_time = time.time()\n        if abs(current_time - signature_obj.timestamp) > tolerance_seconds:\n            return False\n        \n        # Verify tool calls hash\n        expected_tool_hash = self.generate_tool_calls_hash(tool_calls)\n        if expected_tool_hash != signature_obj.tool_calls_hash:\n            return False\n        \n        # Verify reasoning hash if present\n        if signature_obj.reasoning_hash:\n            if not reasoning_text:\n                return False\n            expected_reasoning_hash = self.generate_reasoning_hash(reasoning_text)\n            if expected_reasoning_hash != signature_obj.reasoning_hash:\n                return False\n        \n        # Recreate signature to verify\n        expected_signature = self.create_signature(\n            tool_calls=tool_calls,\n            reasoning_text=reasoning_text,\n            timestamp=signature_obj.timestamp\n        )\n        \n        return expected_signature.signature == signature_obj.signature\n\n\nclass GeminiToolProcessor:\n    \"\"\"\n    Main processor for Gemini 3.0 Pro tool calls with thought signature support.\n    \"\"\"\n    \n    def __init__(self, model: str = \"gemini-3.0-pro\"):\n        \"\"\"\n        Initialize the Gemini tool processor.\n        \n        Args:\n            model: Gemini model name\n        \"\"\"\n        self.model = model\n        self.signature_generator = ThoughtSignatureGenerator(model)\n    \n    def process_with_signature(\n        self,\n        gemini_response: Dict[str, Any],\n        include_reasoning: bool = True\n    ) -> Dict[str, Any]:\n        \"\"\"\n        Process Gemini response and add thought signature.\n        \n        Args:\n            gemini_response: Raw response from Gemini API\n            include_reasoning: Whether to include reasoning in signature\n            \n        Returns:\n            Processed response with thought signature\n        \"\"\"\n        # Extract tool calls from Gemini response\n        tool_calls = self._extract_tool_calls(gemini_response)\n        \n        # Extract reasoning if available and requested\n        reasoning_text = None\n        if include_reasoning:\n            reasoning_text = self._extract_reasoning(gemini_response)\n        \n        # Generate thought signature\n        signature = self.signature_generator.create_signature(\n            tool_calls=tool_calls,\n            reasoning_text=reasoning_text\n        )\n        \n        # Return enhanced response\n        return {\n            \"original_response\": gemini_response,\n            \"tool_calls\": tool_calls,\n            \"reasoning\": reasoning_text,\n            \"thought_signature\": signature.to_dict(),\n            \"metadata\": {\n                \"model\": self.model,\n                \"processed_at\": time.time(),\n                \"signature_valid\": True\n            }\n        }\n    \n    def validate_processed_response(\n        self,\n        processed_response: Dict[str, Any]\n    ) -> bool:\n        \"\"\"\n        Validate a previously processed response.\n        \n        Args:\n            processed_response: Response processed by process_with_signature\n            \n        Returns:\n            True if signature is valid, False otherwise\n        \"\"\"\n        if \"thought_signature\" not in processed_response:\n            return False\n        \n        if \"tool_calls\" not in processed_response:\n            return False\n        \n        # Reconstruct signature object\n        signature_data = processed_response[\"thought_signature\"]\n        signature_obj = ThoughtSignature.from_dict(signature_data)\n        \n        # Get original data\n        tool_calls = processed_response[\"tool_calls\"]\n        reasoning_text = processed_response.get(\"reasoning\")\n        \n        # Validate\n        return self.signature_generator.validate_signature(\n            signature_obj=signature_obj,\n            tool_calls=tool_calls,\n            reasoning_text=reasoning_text\n        )\n    \n    def _extract_tool_calls(self, gemini_response: Dict[str, Any]) -> list:\n        \"\"\"\n        Extract tool calls from Gemini response.\n        \n        Args:\n            gemini_response: Raw Gemini API response\n            \n        Returns:\n            List of tool call dictionaries\n        \"\"\"\n        # This is a simplified extraction - adjust based on actual Gemini API response format\n        tool_calls = []\n        \n        # Check for function calling format\n        if \"candidates\" in gemini_response:\n            for candidate in gemini_response[\"candidates\"]:\n                if \"content\" in candidate and \"parts\" in candidate[\"content\"]:\n                    for part in candidate[\"content\"][\"parts\"]:\n                        if \"functionCall\" in part:\n                            tool_calls.append({\n                                \"function\": part[\"functionCall\"][\"name\"],\n                                \"args\": part[\"functionCall\"].get(\"args\", {})\n                            })\n        \n        return tool_calls\n    \n    def _extract_reasoning(self, gemini_response: Dict[str, Any]) -> Optional[str]:\n        \"\"\"\n        Extract reasoning text from Gemini response.\n        \n        Args:\n            gemini_response: Raw Gemini API response\n            \n        Returns:\n            Reasoning text or None if not available\n        \"\"\"\n        # This is a simplified extraction - adjust based on actual Gemini API response format\n        reasoning_parts = []\n        \n        if \"candidates\" in gemini_response:\n            for candidate in gemini_response[\"candidates\"]:\n                if \"content\" in candidate and \"parts\" in candidate[\"content\"]:\n                    for part in candidate[\"content\"][\"parts\"]:\n                        if isinstance(part, dict) and \"text\" in part:\n                            text = part[\"text\"]\n                            # Simple heuristic: look for reasoning indicators\n                            if any(indicator in text.lower() for indicator in \n                                   [\"reasoning:\", \"thought:\", \"thinking:\", \"step\"]):\n                                reasoning_parts.append(text)\n        \n        return \" \".join(reasoning_parts) if reasoning_parts else None\n\n# filepath: app/agents/__init__.py\n\n\"\"\"\nAgents package for AI tool processing with thought signatures.\n\"\"\"\n\nfrom app.agents.thought_signature import (\n    ThoughtSignature,\n    ThoughtSignatureGenerator,\n    GeminiToolProcessor\n)\n\n__all__ = [\n    \"ThoughtSignature\",\n    \"ThoughtSignatureGenerator\",\n    \"GeminiToolProcessor\"\n]",
      "explanation": "```\n# filepath: tests/test_thought_signature.py\n\"\"\"\nTests for Thought Signature functionality.\n\"\"\"\n\nimport pytest\nimport time\nfrom app.agents.thought_signature import (\n    ThoughtSignature,\n    ThoughtSignatureGenerator,\n    GeminiToolProcessor\n)\n\n\nclass TestThoughtSignature:\n    \"\"\"Test ThoughtSignature dataclass.\"\"\"\n    \n    def test_creation(self):\n        \"\"\"Test creating a ThoughtSignature.\"\"\"\n        signature = ThoughtSignature(\n            model=\"gemini-3.0-pro\",\n            timestamp=1234567890.0,\n            tool_calls_hash=\"abc123\",\n            reasoning_hash=\"def456\",\n            signature=\"final_sig\"\n        )\n        \n        assert signature.model == \"gemini-3.0-pro\"\n        assert signature.timestamp == 1234567890.0\n        assert signature.tool_calls_hash == \"abc123\"\n        assert signature.reasoning_hash == \"def456\"\n        assert signature.signature == \"final_sig\"\n    \n    def test_to_from_dict(self):\n        \"\"\"Test dictionary serialization/deserialization.\"\"\"\n        original = ThoughtSignature(\n            model=\"gemini-3.0-pro\",\n            timestamp=1234567890.0,\n            tool_calls_hash=\"abc123\",\n            reasoning_hash=\"def456\",\n            signature=\"final_sig\"\n        )\n        \n        as_dict = original.to_dict()\n        restored = ThoughtSignature.from_dict(as_dict)\n        \n        assert original == restored\n\n\nclass TestThoughtSignatureGenerator:\n    \"\"\"Test ThoughtSignatureGenerator.\"\"\"\n    \n    def setup_method(self):\n        \"\"\"Setup test fixture.\"\"\"\n        self.generator = ThoughtSignatureGenerator(model=\"gemini-3.0-pro\")\n    \n    def test_generate_tool_calls_hash(self):\n        \"\"\"Test tool calls hash generation.\"\"\"\n        tool_calls = [\n            {\"function\": \"search\", \"args\": {\"query\": \"test\"}},\n            {\"function\": \"calculate\", \"args\": {\"x\": 1, \"y\": 2}}\n        ]\n        \n        hash1 = self.generator.generate_tool_calls_hash(tool_calls)\n        hash2 = self.generator.generate_tool_calls_hash(tool_calls)\n        \n        # Same input should produce same hash\n        assert hash1 == hash2\n        \n        # Different input should produce different hash\n        different_calls = [{\"function\": \"search\", \"args\": {\"query\": \"different\"}}]\n        hash3 = self.generator.generate_tool_calls_hash(different_calls)\n        assert hash1 != hash3\n    \n    def test_generate_reasoning_hash(self):\n        \"\"\"Test reasoning hash generation.\"\"\"\n        reasoning = \"I need to search for information about AI.\"\n        \n        hash1 = self.generator.generate_reasoning_hash(reasoning)\n        hash2 = self.generator.generate_reasoning_hash(reasoning)\n        \n        assert hash1 == hash2\n        \n        # Different reasoning should produce different hash\n        different_reasoning = \"Different reasoning text.\"\n        hash3 = self.generator.generate_reasoning_hash(different_reasoning)\n        assert hash1 != hash3\n    \n    def test_create_signature(self):\n        \"\"\"Test complete signature creation.\"\"\"\n        tool_calls = [{\"function\": \"search\", \"args\": {\"query\": \"test\"}}]\n        reasoning = \"Test reasoning\"\n        \n        signature = self.generator.create_signature(\n            tool_calls=tool_calls,\n            reasoning_text=reasoning\n        )\n        \n        assert signature.model == \"gemini-3.0-pro\"\n        assert signature.timestamp <= time.time()\n        assert signature.tool_calls_hash is not None\n        assert signature.reasoning_hash is not None\n        assert signature.signature is not None\n    \n    def test_validate_signature(self):\n        \"\"\"Test signature validation.\"\"\"\n        tool_calls = [{\"function\": \"search\", \"args\": {\"query\": \"test\"}}]\n        reasoning = \"Test reasoning\"\n        \n        signature = self.generator.create_signature(\n            tool_calls=tool_calls,\n            reasoning_text=reasoning\n        )\n        \n        # Valid signature should pass\n        assert self.generator.validate_signature(\n            signature_obj=signature,\n            tool_calls=tool_calls,\n            reasoning_text=reasoning\n        )\n        \n        # Different tool calls should fail\n        different_calls = [{\"function\": \"search\", \"args\": {\"query\": \"different\"}}]\n        assert not self.generator.validate_signature(\n            signature_obj=signature,\n            tool_calls=different_calls,\n            reasoning_text=reasoning\n        )\n        \n        # Different reasoning should fail\n        different_reasoning = \"Different reasoning\"\n        assert not self.generator.validate_signature(\n            signature_obj=signature,\n            tool_calls=tool_calls,\n            reasoning_text=different_reasoning\n        )\n    \n    def test_validate_signature_timestamp(self):\n        \"\"\"Test timestamp validation with tolerance.\"\"\"\n        tool_calls = [{\"function\": \"search\", \"args\": {\"query\": \"test\"}}]\n        \n        # Create signature with old timestamp\n        old_timestamp = time.time() - 400  # More than 5 minutes old\n        signature = self.generator.create_signature(\n            tool_calls=tool_calls,\n            reasoning_text=None,\n            timestamp=old_timestamp\n        )\n        \n        # Should fail with default tolerance (300 seconds)\n        assert not self.generator.validate_signature(\n            signature_obj=signature,\n            tool_calls=tool_calls,\n            reasoning_text=None\n        )\n        \n        # Should pass with larger tolerance\n        assert self.generator.validate_signature(\n            signature_obj=signature,\n            tool_calls=tool_calls,\n            reasoning_text=None,\n            tolerance_seconds=500\n        )\n\n\nclass TestGeminiToolProcessor:\n    \"\"\"Test GeminiToolProcessor.\"\"\"\n    \n    def setup_method(self):\n        \"\"\"Setup test fixture.\"\"\"\n        self.processor = GeminiToolProcessor(model=\"gemini-3.0-pro\")\n    \n    def test_process_with_signature(self):\n        \"\"\"Test processing Gemini response with signature.\"\"\"\n        # Mock Gemini response\n        gemini_response = {\n            \"candidates\": [{\n                \"content\": {\n                    \"parts\": [\n                        {\"text\": \"Reasoning: I need to search for AI information.\"},\n                        {\"functionCall\": {\n                            \"name\": \"search\",\n                            \"args\": {\"query\": \"artificial intelligence\"}\n                        }}\n                    ]\n                }\n            }]\n        }\n        \n        processed = self.processor.process_with_signature(\n            gemini_response=gemini_response,\n            include_reasoning=True\n        )\n        \n        assert \"original_response\" in processed\n        assert \"tool_calls\" in processed\n        assert \"reasoning\" in processed\n        assert \"thought_signature\" in processed\n        assert \"metadata\" in processed\n        \n        # Should have extracted tool calls\n        assert len(processed[\"tool_calls\"]) > 0\n        \n        # Should have extracted reasoning\n        assert processed[\"reasoning\"] is not None\n        \n        # Signature should be valid\n        assert processed[\"metadata\"][\"signature_valid\"] is True\n    \n    def test_validate_processed_response(self):\n        \"\"\"Test validation of processed response.\"\"\"\n        # Create a processed response\n        gemini_response = {\n            \"candidates\": [{\n                \"content\": {\n                    \"parts\": [\n                        {\"functionCall\": {\n                            \"name\": \"calculate\",\n                            \"args\": {\"x\": 5, \"y\": 3}\n                        }}\n                    ]\n                }\n            }]\n        }\n        \n        processed = self.processor.process_with_signature(\n            gemini_response=gemini_response,\n            include_reasoning=False\n        )\n        \n        # Should validate successfully\n        assert self.processor.validate_processed_response(processed)\n        \n        # Tampered response should fail\n        tampered = processed.copy()\n        tampered[\"tool_calls\"][0][\"args\"][\"x\"] = 10  # Change argument\n        \n        assert not self.processor.validate_processed_response(tampered)\n    \n    def test_extract_tool_calls(self):\n        \"\"\"Test tool call extraction.\"\"\"",
      "error": null,
      "model_used": "deepseek-chat",
      "tokens_used": 0
    }
  }
}