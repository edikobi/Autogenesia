{
  "metadata": {
    "timestamp": "2025-12-14T23:15:29.198356",
    "project_dir": "C:\\Users\\Admin\\AI_Assistant_Pro",
    "user_query": "Ты начал писать файл, но он обрывается на середине и не содержит главной логики.Также ты пытаешься импортировать несуществующие промпты (`format_compression_prompt`).**Требования к исправлению:**1.  **Допиши файл до конца.** В нем должны быть реализованы две главные публичные функции:    *   `compress_history_if_needed(history: List[Message], threshold: int) -> List[Message]`    *   `prune_irrelevant_context(history: List[Message], current_query: str) -> List[Message]`2.  **Промпты внутри кода:**    *   Не импортируй промпты. Определи их как константы прямо в этом файле:        *   `TOOL_COMPRESSION_PROMPT`: \"Ты — AI-аналитик... сожми до 20%... оставь факты...\"        *   `ASSISTANT_COMPRESSION_PROMPT`: \"Ты — AI-аналитик... сожми до 30%... сохрани логику...\"3.  **Логика `compress_history_if_needed`:**    *   Посчитай `total_tokens` через `token_counter`.    *   Если < `threshold`, верни `history` (копию).    *   Если больше:        *   Последние 3 сообщения (`history[-3:]`) оставь как есть.        *   Остальные (`history[:-3]`) обрабатывай:            *   `user` → не трогать.            *   `assistant` с блоками кода (```            *   `assistant` без кода → вызови LLM с `ASSISTANT_COMPRESSION_PROMPT`.            *   `tool` → вызови LLM с `TOOL_COMPRESSION_PROMPT`.    *   Если вызов LLM упал (try/except), верни оригинальное сообщение.    *   Добавь префикс `[COMPRESSED]` к сжатому тексту.4.  **Логика `prune_irrelevant_context`:**    *   Используй свою функцию `_extract_file_paths` для анализа `current_query`.    *   Если в запросе нет файлов, верни историю как есть (нельзя прунить, если не знаем контекст).    *   Если файлы есть:        *   Проходи по сообщениям `role='tool'`.        *   Если в tool output упоминаются файлы, которых НЕТ в запросе → замени контент на `[PRUNED: ...]`.5.  **Импорты:**    *   Убедись, что импорт `call_llm` (или клиента) корректен. Если нужно, используй заглушку или стандартный `app.llm.api_client`.**Выдай ПОЛНЫЙ код файла `compressor.py` без обрывов.**",
    "duration_seconds": 186.81365776062012,
    "models_used": {
      "orchestrator": "Claude Opus 4.5 (RouterAI)",
      "code_generator": "deepseek-chat"
    }
  },
  "orchestrator": {
    "analysis": "Файл `app/history/compressor.py` имеет следующие проблемы:\n\n1. **Обрывается на середине** - функция `_contains_code_block` не завершена (строка 63 обрывается на `if '`)\n2. **Импорт несуществующего промпта** - хотя `format_compression_prompt` существует в `prompt_templates.py`, пользователь требует определить промпты локально\n3. **Отсутствуют главные функции** - `compress_history_if_needed` и `prune_irrelevant_context` не реализованы\n4. **Асинхронность** - `call_llm` является асинхронной функцией, поэтому функции сжатия тоже должны быть асинхронными\n\nТребуется полностью переписать файл с:\n- Локальными константами промптов `TOOL_COMPRESSION_PROMPT` и `ASSISTANT_COMPRESSION_PROMPT`\n- Завершённой функцией `_contains_code_block`\n- Реализацией `compress_history_if_needed` с логикой:\n  - Подсчёт токенов\n  - Сохранение последних 3 сообщений\n  - Сжатие `assistant` (без кода) и `tool` через LLM\n  - Обработка ошибок с возвратом оригинала\n  - Префикс `[COMPRESSED]`\n- Реализацией `prune_irrelevant_context` с логикой:\n  - Извлечение файлов из запроса\n  - Замена нерелевантных tool outputs на `[PRUNED: ...]`",
    "instruction": "**Task:** Полностью переписать файл `compressor.py` с реализацией всех функций сжатия истории\n\n**File:** `app/history/compressor.py`\n\n**Location:** Полная замена содержимого файла\n\n**Changes:**\n\n1. **Импорты (строки 1-20):**\n   - Удалить импорт `from app.llm.prompt_templates import format_compression_prompt`\n   - Оставить импорты: `re`, `logging`, `asyncio` (добавить), `List`, `Dict`, `Any`, `Optional`, `Set` из `typing`, `dataclasses.replace`\n   - Оставить: `from app.history.storage import Message`\n   - Оставить: `from app.utils.token_counter import TokenCounter`\n   - Оставить: `from app.llm.api_client import call_llm`\n   - Оставить: `from config.settings import cfg`\n   - Создать `logger = logging.getLogger(__name__)` и `token_counter = TokenCounter()`\n\n2. **Добавить константы промптов (после импортов, перед функциями):**\n   ```python\n   TOOL_COMPRESSION_PROMPT = \"\"\"Ты — AI-аналитик. Сожми следующий результат работы инструмента до ~20% от оригинального размера.\n\n   СОХРАНИ:\n   - Ключевые находки и выводы\n   - Важные фрагменты кода (сократи до существенных строк)\n   - Имена файлов и номера строк\n   - Сообщения об ошибках (если есть)\n\n   УДАЛИ:\n   - Полные листинги кода (оставь только релевантные выдержки)\n   - Многословный/избыточный вывод\n   - Дублирующуюся информацию\n   - Лишние пробелы и форматирование\n\n   Оригинальный результат инструмента:\n   {content}\n\n   Сжатая версия:\"\"\"\n\n   ASSISTANT_COMPRESSION_PROMPT = \"\"\"Ты — AI-аналитик. Сожми следующее рассуждение/анализ до ~30% от оригинального размера.\n\n   СОХРАНИ:\n   - Главные выводы и решения\n   - Ключевые находки, влияющие на решение\n   - Важные оговорки или предупреждения\n   - Логику принятия решений\n\n   УДАЛИ:\n   - Пошаговый процесс рассуждений\n   - Многословные объяснения\n   - Альтернативные подходы, которые были отвергнуты\n   - Повторяющиеся утверждения\n\n   Оригинальное рассуждение:\n   {content}\n\n   Сжатая версия:\"\"\"\n   ```\n\n3. **Функция `_extract_file_paths` (оставить как есть, строки ~23-49):**\n   - Функция уже реализована корректно, оставить без изменений\n\n4. **Завершить функцию `_contains_code_block` (строки ~52-70):**\n   ```python\n   def _contains_code_block(text: str) -> bool:\n       \"\"\"Проверяет, содержит ли текст блоки кода.\"\"\"\n       if not text:\n           return False\n       # Проверка на блоки кода в markdown (тройные обратные кавычки)\n       if '```' in text:\n           return True\n       # Проверка на XML-обёрнутый код\n       if '<code>' in text or '<CODE>' in text:\n           return True\n       return False\n   ```\n\n5. **Добавить асинхронную функцию `_compress_with_llm` (после `_contains_code_block`):**\n   ```python\n   async def _compress_with_llm(content: str, prompt_template: str) -> Optional[str]:\n       \"\"\"\n       Сжимает контент с помощью LLM.\n       \n       Args:\n           content: Контент для сжатия\n           prompt_template: Шаблон промпта (TOOL_COMPRESSION_PROMPT или ASSISTANT_COMPRESSION_PROMPT)\n       \n       Returns:\n           Сжатый контент или None при ошибке\n       \"\"\"\n       try:\n           prompt = prompt_template.format(content=content)\n           messages = [{\"role\": \"user\", \"content\": prompt}]\n           \n           # Используем быструю модель для сжатия (Gemini 2.0 Flash или аналог)\n           model = getattr(cfg, 'COMPRESSION_MODEL', 'google/gemini-2.0-flash-001')\n           \n           result = await call_llm(\n               model=model,\n               messages=messages,\n               temperature=0.0,\n               max_tokens=2000\n           )\n           return result\n       except Exception as e:\n           logger.warning(f\"Ошибка при сжатии через LLM: {e}\")\n           return None\n   ```\n\n6. **Добавить главную функцию `compress_history_if_needed` (асинхронная):**\n   ```python\n   async def compress_history_if_needed(history: List[Message], threshold: int) -> List[Message]:\n       \"\"\"\n       Сжимает историю диалога, если общее количество токенов превышает порог.\n       \n       Args:\n           history: Список сообщений для обработки\n           threshold: Порог токенов, после которого начинается сжатие\n       \n       Returns:\n           Список сообщений (возможно сжатых)\n       \"\"\"\n       if not history:\n           return []\n       \n       # Подсчитываем общее количество токенов\n       total_tokens = sum(\n           msg.tokens if msg.tokens > 0 else token_counter.count(msg.content)\n           for msg in history\n       )\n       \n       # Если меньше порога - возвращаем копию без изменений\n       if total_tokens < threshold:\n           return [replace(msg) for msg in history]\n       \n       logger.info(f\"Сжатие истории: {total_tokens} токенов > {threshold} порог\")\n       \n       # Последние 3 сообщения оставляем как есть\n       if len(history) <= 3:\n           return [replace(msg) for msg in history]\n       \n       messages_to_compress = history[:-3]\n       recent_messages = history[-3:]\n       \n       compressed_messages = []\n       \n       for msg in messages_to_compress:\n           # user сообщения не трогаем\n           if msg.role == 'user':\n               compressed_messages.append(replace(msg))\n               continue\n           \n           # assistant с блоками кода - не трогаем\n           if msg.role == 'assistant' and _contains_code_block(msg.content):\n               compressed_messages.append(replace(msg))\n               continue\n           \n           # assistant без кода - сжимаем\n           if msg.role == 'assistant':\n               compressed_content = await _compress_with_llm(msg.content, ASSISTANT_COMPRESSION_PROMPT)\n               if compressed_content:\n                   new_content = f\"[COMPRESSED] {compressed_content}\"\n                   new_tokens = token_counter.count(new_content)\n                   compressed_messages.append(replace(msg, content=new_content, tokens=new_tokens))\n               else:\n                   # При ошибке возвращаем оригинал\n                   compressed_messages.append(replace(msg))\n               continue\n           \n           # tool - сжимаем\n           if msg.role == 'tool':\n               compressed_content = await _compress_with_llm(msg.content, TOOL_COMPRESSION_PROMPT)\n               if compressed_content:\n                   new_content = f\"[COMPRESSED] {compressed_content}\"\n                   new_tokens = token_counter.count(new_content)\n                   compressed_messages.append(replace(msg, content=new_content, tokens=new_tokens))\n               else:\n                   # При ошибке возвращаем оригинал\n                   compressed_messages.append(replace(msg))\n               continue\n           \n           # Остальные роли (system и др.) - оставляем как есть\n           compressed_messages.append(replace(msg))\n       \n       # Добавляем последние 3 сообщения без изменений\n       for msg in recent_messages:\n           compressed_messages.append(replace(msg))\n       \n       return compressed_messages\n   ```\n\n7. **Добавить функцию `prune_irrelevant_context`:**\n   ```python\n   def prune_irrelevant_context(history: List[Message], current_query: str) -> List[Message]:\n       \"\"\"\n       Удаляет нерелевантные результаты инструментов на основе текущего запроса.\n       \n       Args:\n           history: Список сообщений\n           current_query: Текущий запрос пользователя\n       \n       Returns:\n           Список сообщений с обрезанными нерелевантными tool outputs\n       \"\"\"\n       if not history:\n           return []\n       \n       # Извлекаем файлы из текущего запроса\n       query_files = _extract_file_paths(current_query)\n       \n       # Если в запросе нет файлов - не можем определить релевантность, возвращаем как есть\n       if not query_files:\n           return [replace(msg) for msg in history]\n       \n       logger.debug(f\"Файлы в запросе: {query_files}\")\n       \n       pruned_messages = []\n       \n       for msg in history:\n           # Обрабатываем только tool сообщения\n           if msg.role != 'tool':\n               pruned_messages.append(replace(msg))\n               continue\n           \n           # Извлекаем файлы из tool output\n           tool_files = _extract_file_paths(msg.content)\n           \n           # Если в tool output нет файлов - оставляем как есть\n           if not tool_files:\n               pruned_messages.append(replace(msg))\n               continue\n           \n           # Проверяем, есть ли пересечение с файлами из запроса\n           relevant_files = query_files & tool_files\n           \n           if relevant_files:\n               # Есть релевантные файлы - оставляем сообщение\n               pruned_messages.append(replace(msg))\n           else:\n               # Нет релевантных файлов - обрезаем\n               # Извлекаем первые несколько файлов для информативности\n               mentioned_files = list(tool_files)[:3]\n               files_str = \", \".join(mentioned_files)\n               if len(tool_files) > 3:\n                   files_str += f\" и ещё {len(tool_files) - 3}\"\n               \n               pruned_content = f\"[PRUNED: tool output о файлах {files_str}, не релевантных текущему запросу]\"\n               new_tokens = token_counter.count(pruned_content)\n               pruned_messages.append(replace(msg, content=pruned_content, tokens=new_tokens))\n               logger.debug(f\"Обрезано tool сообщение о файлах: {tool_files}\")\n       \n       return pruned_messages\n   ```\n\n**Why:** Файл был незавершён и содержал импорт, который пользователь хочет заменить на локальные константы. Требуется полная реализация функционала сжатия истории для управления контекстом в диалогах с LLM."
  },
  "code_generator": {
    "code_blocks": [
      {
        "filepath": "app/history/compressor.py",
        "language": "python",
        "code": "\"\"\"\nМодуль для сжатия истории диалога на лету без сохранения в БД (режим Recompute).\nРеализует две основные стратегии:\n1. Токен-базированное сжатие: сжимает старые сообщения с помощью быстрой LLM (Gemini 2.0 Flash),\n   сохраняя сообщения пользователя и блоки кода.\n2. Обрезка контекста: удаляет нерелевантные результаты инструментов на основе текущего запроса.\n\"\"\"\n\nimport re\nimport logging\nimport asyncio\nfrom typing import List, Dict, Any, Optional, Set\nfrom dataclasses import replace\nfrom app.history.storage import Message\nfrom app.utils.token_counter import TokenCounter\nfrom app.llm.api_client import call_llm\nfrom config.settings import cfg\n\nlogger = logging.getLogger(__name__)\ntoken_counter = TokenCounter()\n\nTOOL_COMPRESSION_PROMPT = \"\"\"Ты — AI-аналитик. Сожми следующий результат работы инструмента до ~20% от оригинального размера.\n\nСОХРАНИ:\n- Ключевые находки и выводы\n- Важные фрагменты кода (сократи до существенных строк)\n- Имена файлов и номера строк\n- Сообщения об ошибках (если есть)\n\nУДАЛИ:\n- Полные листинги кода (оставь только релевантные выдержки)\n- Многословный/избыточный вывод\n- Дублирующуюся информацию\n- Лишние пробелы и форматирование\n\nОригинальный результат инструмента:\n{content}\n\nСжатая версия:\"\"\"\n\nASSISTANT_COMPRESSION_PROMPT = \"\"\"Ты — AI-аналитик. Сожми следующее рассуждение/анализ до ~30% от оригинального размера.\n\nСОХРАНИ:\n- Главные выводы и решения\n- Ключевые находки, влияющие на решение\n- Важные оговорки или предупреждения\n- Логику принятия решений\n\nУДАЛИ:\n- Пошаговый процесс рассуждений\n- Многословные объяснения\n- Альтернативные подходы, которые были отвергнуты\n- Повторяющиеся утверждения\n\nОригинальное рассуждение:\n{content}\n\nСжатая версия:\"\"\"\n\n\ndef _extract_file_paths(text: str) -> Set[str]:\n    \"\"\"\n    Извлекает пути к файлам из текста с помощью регулярных выражений.\n\n    Args:\n        text: Текст для анализа.\n\n    Returns:\n        Множество уникальных путей к файлам, найденных в тексте.\n    \"\"\"\n    if not text:\n        return set()\n\n    # Регулярное выражение для поиска путей к файлам\n    pattern = r'(?:^|[\\s\"\\'\\(])([a-zA-Z0-9_\\-./\\\\]+\\.[a-zA-Z0-9]+)(?:[\\s\"\\'\\)]|$)'\n    # Дополнительные паттерны для общих путей\n    common_path_pattern = r'(?:^|[\\s\"\\'\\(])((?:app|src|config|tests|scripts)/[a-zA-Z0-9_\\-./\\\\]+)(?:[\\s\"\\'\\)]|$)'\n\n    file_paths = set()\n    # Ищем файлы с расширениями\n    for match in re.finditer(pattern, text):\n        file_paths.add(match.group(1))\n    # Ищем общие пути\n    for match in re.finditer(common_path_pattern, text):\n        file_paths.add(match.group(1))\n\n    return file_paths\n\n\ndef _contains_code_block(text: str) -> bool:\n    \"\"\"Проверяет, содержит ли текст блоки кода.\"\"\"\n    if not text:\n        return False\n    # Проверка на блоки кода в markdown (тройные обратные кавычки)\n    if '",
        "context": null
      },
      {
        "filepath": "app/history/compressor.py",
        "language": "python",
        "code": "### Explanation\n\nЭтот код полностью переписывает модуль `compressor.py`, реализуя функционал сжатия истории диалога для управления контекстом в LLM-диалогах. Основные изменения:\n\n**1. Структура импортов:**\n- Удалён импорт `format_compression_prompt` из `app.llm.prompt_templates`\n- Добавлен импорт `asyncio` для асинхронных операций\n- Сохранены все необходимые импорты для работы с сообщениями, токенами и LLM API\n\n**2. Локальные промпты:**\n- Добавлены две константы промптов (`TOOL_COMPRESSION_PROMPT` и `ASSISTANT_COMPRESSION_PROMPT`) прямо в файл\n- Каждый промпт содержит специфичные инструкции для сжатия разных типов контента (результаты инструментов vs рассуждения ассистента)\n\n**3. Завершённые функции:**\n- `_contains_code_block` теперь корректно проверяет наличие блоков кода через маркеры",
        "context": null
      }
    ],
    "explanation": "Этот код полностью переписывает модуль `compressor.py`, реализуя функционал сжатия истории диалога для управления контекстом в LLM-диалогах. Основные изменения:\n\n**1. Структура импортов:**\n- Удалён импорт `format_compression_prompt` из `app.llm.prompt_templates`\n- Добавлен импорт `asyncio` для асинхронных операций\n- Сохранены все необходимые импорты для работы с сообщениями, токенами и LLM API\n\n**2. Локальные промпты:**\n- Добавлены две константы промптов (`TOOL_COMPRESSION_PROMPT` и `ASSISTANT_COMPRESSION_PROMPT`) прямо в файл\n- Каждый промпт содержит специфичные инструкции для сжатия разных типов контента (результаты инструментов vs рассуждения ассистента)\n\n**3. Завершённые функции:**\n- `_contains_code_block` теперь корректно проверяет наличие блоков кода через маркеры ` не сжимается для сохранения точности",
    "frontend_json": {
      "success": true,
      "code_blocks": [
        {
          "code": "\"\"\"\nМодуль для сжатия истории диалога на лету без сохранения в БД (режим Recompute).\nРеализует две основные стратегии:\n1. Токен-базированное сжатие: сжимает старые сообщения с помощью быстрой LLM (Gemini 2.0 Flash),\n   сохраняя сообщения пользователя и блоки кода.\n2. Обрезка контекста: удаляет нерелевантные результаты инструментов на основе текущего запроса.\n\"\"\"\n\nimport re\nimport logging\nimport asyncio\nfrom typing import List, Dict, Any, Optional, Set\nfrom dataclasses import replace\nfrom app.history.storage import Message\nfrom app.utils.token_counter import TokenCounter\nfrom app.llm.api_client import call_llm\nfrom config.settings import cfg\n\nlogger = logging.getLogger(__name__)\ntoken_counter = TokenCounter()\n\nTOOL_COMPRESSION_PROMPT = \"\"\"Ты — AI-аналитик. Сожми следующий результат работы инструмента до ~20% от оригинального размера.\n\nСОХРАНИ:\n- Ключевые находки и выводы\n- Важные фрагменты кода (сократи до существенных строк)\n- Имена файлов и номера строк\n- Сообщения об ошибках (если есть)\n\nУДАЛИ:\n- Полные листинги кода (оставь только релевантные выдержки)\n- Многословный/избыточный вывод\n- Дублирующуюся информацию\n- Лишние пробелы и форматирование\n\nОригинальный результат инструмента:\n{content}\n\nСжатая версия:\"\"\"\n\nASSISTANT_COMPRESSION_PROMPT = \"\"\"Ты — AI-аналитик. Сожми следующее рассуждение/анализ до ~30% от оригинального размера.\n\nСОХРАНИ:\n- Главные выводы и решения\n- Ключевые находки, влияющие на решение\n- Важные оговорки или предупреждения\n- Логику принятия решений\n\nУДАЛИ:\n- Пошаговый процесс рассуждений\n- Многословные объяснения\n- Альтернативные подходы, которые были отвергнуты\n- Повторяющиеся утверждения\n\nОригинальное рассуждение:\n{content}\n\nСжатая версия:\"\"\"\n\n\ndef _extract_file_paths(text: str) -> Set[str]:\n    \"\"\"\n    Извлекает пути к файлам из текста с помощью регулярных выражений.\n\n    Args:\n        text: Текст для анализа.\n\n    Returns:\n        Множество уникальных путей к файлам, найденных в тексте.\n    \"\"\"\n    if not text:\n        return set()\n\n    # Регулярное выражение для поиска путей к файлам\n    pattern = r'(?:^|[\\s\"\\'\\(])([a-zA-Z0-9_\\-./\\\\]+\\.[a-zA-Z0-9]+)(?:[\\s\"\\'\\)]|$)'\n    # Дополнительные паттерны для общих путей\n    common_path_pattern = r'(?:^|[\\s\"\\'\\(])((?:app|src|config|tests|scripts)/[a-zA-Z0-9_\\-./\\\\]+)(?:[\\s\"\\'\\)]|$)'\n\n    file_paths = set()\n    # Ищем файлы с расширениями\n    for match in re.finditer(pattern, text):\n        file_paths.add(match.group(1))\n    # Ищем общие пути\n    for match in re.finditer(common_path_pattern, text):\n        file_paths.add(match.group(1))\n\n    return file_paths\n\n\ndef _contains_code_block(text: str) -> bool:\n    \"\"\"Проверяет, содержит ли текст блоки кода.\"\"\"\n    if not text:\n        return False\n    # Проверка на блоки кода в markdown (тройные обратные кавычки)\n    if '",
          "filepath": "app/history/compressor.py",
          "language": "python",
          "context": null
        },
        {
          "code": "### Explanation\n\nЭтот код полностью переписывает модуль `compressor.py`, реализуя функционал сжатия истории диалога для управления контекстом в LLM-диалогах. Основные изменения:\n\n**1. Структура импортов:**\n- Удалён импорт `format_compression_prompt` из `app.llm.prompt_templates`\n- Добавлен импорт `asyncio` для асинхронных операций\n- Сохранены все необходимые импорты для работы с сообщениями, токенами и LLM API\n\n**2. Локальные промпты:**\n- Добавлены две константы промптов (`TOOL_COMPRESSION_PROMPT` и `ASSISTANT_COMPRESSION_PROMPT`) прямо в файл\n- Каждый промпт содержит специфичные инструкции для сжатия разных типов контента (результаты инструментов vs рассуждения ассистента)\n\n**3. Завершённые функции:**\n- `_contains_code_block` теперь корректно проверяет наличие блоков кода через маркеры",
          "filepath": "app/history/compressor.py",
          "language": "python",
          "context": null
        }
      ],
      "combined_code": "\n\n# ==================================================# filepath: app/history/compressor.py\n\n\"\"\"\nМодуль для сжатия истории диалога на лету без сохранения в БД (режим Recompute).\nРеализует две основные стратегии:\n1. Токен-базированное сжатие: сжимает старые сообщения с помощью быстрой LLM (Gemini 2.0 Flash),\n   сохраняя сообщения пользователя и блоки кода.\n2. Обрезка контекста: удаляет нерелевантные результаты инструментов на основе текущего запроса.\n\"\"\"\n\nimport re\nimport logging\nimport asyncio\nfrom typing import List, Dict, Any, Optional, Set\nfrom dataclasses import replace\nfrom app.history.storage import Message\nfrom app.utils.token_counter import TokenCounter\nfrom app.llm.api_client import call_llm\nfrom config.settings import cfg\n\nlogger = logging.getLogger(__name__)\ntoken_counter = TokenCounter()\n\nTOOL_COMPRESSION_PROMPT = \"\"\"Ты — AI-аналитик. Сожми следующий результат работы инструмента до ~20% от оригинального размера.\n\nСОХРАНИ:\n- Ключевые находки и выводы\n- Важные фрагменты кода (сократи до существенных строк)\n- Имена файлов и номера строк\n- Сообщения об ошибках (если есть)\n\nУДАЛИ:\n- Полные листинги кода (оставь только релевантные выдержки)\n- Многословный/избыточный вывод\n- Дублирующуюся информацию\n- Лишние пробелы и форматирование\n\nОригинальный результат инструмента:\n{content}\n\nСжатая версия:\"\"\"\n\nASSISTANT_COMPRESSION_PROMPT = \"\"\"Ты — AI-аналитик. Сожми следующее рассуждение/анализ до ~30% от оригинального размера.\n\nСОХРАНИ:\n- Главные выводы и решения\n- Ключевые находки, влияющие на решение\n- Важные оговорки или предупреждения\n- Логику принятия решений\n\nУДАЛИ:\n- Пошаговый процесс рассуждений\n- Многословные объяснения\n- Альтернативные подходы, которые были отвергнуты\n- Повторяющиеся утверждения\n\nОригинальное рассуждение:\n{content}\n\nСжатая версия:\"\"\"\n\n\ndef _extract_file_paths(text: str) -> Set[str]:\n    \"\"\"\n    Извлекает пути к файлам из текста с помощью регулярных выражений.\n\n    Args:\n        text: Текст для анализа.\n\n    Returns:\n        Множество уникальных путей к файлам, найденных в тексте.\n    \"\"\"\n    if not text:\n        return set()\n\n    # Регулярное выражение для поиска путей к файлам\n    pattern = r'(?:^|[\\s\"\\'\\(])([a-zA-Z0-9_\\-./\\\\]+\\.[a-zA-Z0-9]+)(?:[\\s\"\\'\\)]|$)'\n    # Дополнительные паттерны для общих путей\n    common_path_pattern = r'(?:^|[\\s\"\\'\\(])((?:app|src|config|tests|scripts)/[a-zA-Z0-9_\\-./\\\\]+)(?:[\\s\"\\'\\)]|$)'\n\n    file_paths = set()\n    # Ищем файлы с расширениями\n    for match in re.finditer(pattern, text):\n        file_paths.add(match.group(1))\n    # Ищем общие пути\n    for match in re.finditer(common_path_pattern, text):\n        file_paths.add(match.group(1))\n\n    return file_paths\n\n\ndef _contains_code_block(text: str) -> bool:\n    \"\"\"Проверяет, содержит ли текст блоки кода.\"\"\"\n    if not text:\n        return False\n    # Проверка на блоки кода в markdown (тройные обратные кавычки)\n    if '\n\n# filepath: app/history/compressor.py\n\n### Explanation\n\nЭтот код полностью переписывает модуль `compressor.py`, реализуя функционал сжатия истории диалога для управления контекстом в LLM-диалогах. Основные изменения:\n\n**1. Структура импортов:**\n- Удалён импорт `format_compression_prompt` из `app.llm.prompt_templates`\n- Добавлен импорт `asyncio` для асинхронных операций\n- Сохранены все необходимые импорты для работы с сообщениями, токенами и LLM API\n\n**2. Локальные промпты:**\n- Добавлены две константы промптов (`TOOL_COMPRESSION_PROMPT` и `ASSISTANT_COMPRESSION_PROMPT`) прямо в файл\n- Каждый промпт содержит специфичные инструкции для сжатия разных типов контента (результаты инструментов vs рассуждения ассистента)\n\n**3. Завершённые функции:**\n- `_contains_code_block` теперь корректно проверяет наличие блоков кода через маркеры",
      "explanation": "Этот код полностью переписывает модуль `compressor.py`, реализуя функционал сжатия истории диалога для управления контекстом в LLM-диалогах. Основные изменения:\n\n**1. Структура импортов:**\n- Удалён импорт `format_compression_prompt` из `app.llm.prompt_templates`\n- Добавлен импорт `asyncio` для асинхронных операций\n- Сохранены все необходимые импорты для работы с сообщениями, токенами и LLM API\n\n**2. Локальные промпты:**\n- Добавлены две константы промптов (`TOOL_COMPRESSION_PROMPT` и `ASSISTANT_COMPRESSION_PROMPT`) прямо в файл\n- Каждый промпт содержит специфичные инструкции для сжатия разных типов контента (результаты инструментов vs рассуждения ассистента)\n\n**3. Завершённые функции:**\n- `_contains_code_block` теперь корректно проверяет наличие блоков кода через маркеры ` не сжимается для сохранения точности",
      "error": null,
      "model_used": "deepseek-chat",
      "tokens_used": 0
    }
  }
}