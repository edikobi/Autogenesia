#!/usr/bin/env python3
# scripts/test_orchestrator_raw.py
"""
–î–∏–∞–≥–Ω–æ—Å—Ç–∏—á–µ—Å–∫–∏–π —Å–∫—Ä–∏–ø—Ç –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ —Å—ã—Ä–æ–≥–æ –≤—ã–≤–æ–¥–∞ Orchestrator.

–¶–ï–õ–¨: –ü–æ–Ω—è—Ç—å, –≥–¥–µ —Ç–µ—Ä—è–µ—Ç—Å—è –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏—è ‚Äî –ø—Ä–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∏–ª–∏ –ø—Ä–∏ –ø–∞—Ä—Å–∏–Ω–≥–µ.

–í—ã–≤–æ–¥–∏—Ç:
1. –°—ã—Ä–æ–π –æ—Ç–≤–µ—Ç –º–æ–¥–µ–ª–∏ (raw_response) - –±–µ–∑ –æ–±—Ä–∞–±–æ—Ç–∫–∏
2. –†–∞—Å–ø–∞—Ä—Å–µ–Ω–Ω—ã–π analysis
3. –†–∞—Å–ø–∞—Ä—Å–µ–Ω–Ω—É—é instruction
4. –°—Ä–∞–≤–Ω–µ–Ω–∏–µ –¥–ª–∏–Ω

–ë–µ–∑ Code Generator ‚Äî —Ç–æ–ª—å–∫–æ –¥–æ –æ—Ä–∫–µ—Å—Ç—Ä–∞—Ç–æ—Ä–∞.
"""

from __future__ import annotations
import asyncio
import json
import sys
import time
from datetime import datetime
from pathlib import Path
from typing import Dict, List, Optional, Any
import re

# –î–æ–±–∞–≤–ª—è–µ–º –∫–æ—Ä–µ–Ω—å –ø—Ä–æ–µ–∫—Ç–∞ –≤ –ø—É—Ç—å
PROJECT_ROOT = Path(__file__).resolve().parent.parent
sys.path.insert(0, str(PROJECT_ROOT))


# ============================================================================
# –¶–í–ï–¢–ê
# ============================================================================

class Colors:
    RESET = "\033[0m"
    BOLD = "\033[1m"
    DIM = "\033[2m"
    RED = "\033[91m"
    GREEN = "\033[92m"
    YELLOW = "\033[93m"
    BLUE = "\033[94m"
    MAGENTA = "\033[95m"
    CYAN = "\033[96m"


def print_header(text: str, char: str = "="):
    width = 80
    print(f"\n{Colors.CYAN}{char * width}")
    print(f"{Colors.BOLD}{text.center(width)}")
    print(f"{char * width}{Colors.RESET}\n")


def print_section(title: str):
    print(f"\n{Colors.YELLOW}{'‚îÄ' * 60}")
    print(f"{Colors.BOLD}  {title}")
    print(f"{'‚îÄ' * 60}{Colors.RESET}\n")


def print_success(text: str):
    print(f"{Colors.GREEN}‚úÖ {text}{Colors.RESET}")


def print_error(text: str):
    print(f"{Colors.RED}‚ùå {text}{Colors.RESET}")


def print_warning(text: str):
    print(f"{Colors.YELLOW}‚ö†Ô∏è  {text}{Colors.RESET}")


def print_info(text: str):
    print(f"{Colors.BLUE}‚ÑπÔ∏è  {text}{Colors.RESET}")


def print_metric(label: str, value: Any, threshold: Optional[int] = None):
    """–í—ã–≤–æ–¥–∏—Ç –º–µ—Ç—Ä–∏–∫—É —Å —Ü–≤–µ—Ç–æ–≤–æ–π –∏–Ω–¥–∏–∫–∞—Ü–∏–µ–π"""
    if threshold and isinstance(value, (int, float)):
        color = Colors.GREEN if value >= threshold else Colors.RED
    else:
        color = Colors.RESET
    print(f"  ‚Ä¢ {label}: {color}{value}{Colors.RESET}")


# ============================================================================
# –¢–ï–°–¢–û–í–´–ï –ó–ê–ü–†–û–°–´
# ============================================================================

TEST_QUERIES = [
    {
        "id": "gemini_integration",
        "query": """–Ø —Ö–æ—á—É –≤–Ω–µ–¥—Ä–∏—Ç—å –µ—â–µ –æ–¥–Ω—É –º–æ–¥–µ–ª—å –ò–ò –¥–ª—è –û—Ä–∫–µ—Å—Ç—Ä–∞—Ç–æ—Ä–∞ (–ø—Ä–æ—Å—Ç–æ –¥–ª—è –≤—ã–±–æ—Ä–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è, –∫–∞–∫ Deepseek V3.2 —Ä–∞—Å—Å—É–∂–¥–∞—é—â–∏–π), –∞ –∏–º–µ–Ω–Ω–æ Gemini 3.0 pro. –ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π —Ñ–∞–π–ª—ã –ø—Ä–æ–µ–∫—Ç–∞, –æ—Å–æ–±–µ–Ω–Ω–æ settings.py, orchestrator.py, api_client.py –∏ —É–∫–∞–∂–∏, —É—á–∏—Ç—ã–≤–∞—è –æ—Å–æ–±–µ–Ω–Ω–æ—Å—Ç—å —ç—Ç–æ–π –º–æ–¥–µ–ª–∏ –ø—Ä–∏ —Ä–∞–±–æ—Ç–µ —Å –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–∞–º–∏ (–Ω–∞–¥–æ –ø–∞—Ä—Å–∏—Ç—å –∏ –≤–æ–∑–≤—Ä–∞—â–∞—Ç—å Thought Signatures –Ω–∞–∑–∞–¥), —Ç–æ –∫–∞–∫ –∞–∫–∫—É—Ä–∞—Ç–Ω–æ –≤–Ω–µ–¥—Ä–∏—Ç—å —ç—Ç—É –º–æ–¥–µ–ª—å, —á—Ç–æ–±—ã –Ω–µ –∏—Å–ø–æ—Ä—Ç–∏—Ç—å —Ä–∞–±–æ—Ç—É –æ—Å—Ç–∞–ª—å–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π. –í–∞–∂–Ω–æ (!) –∏—â–∏ –≤ –ò–Ω—Ç–µ—Ä–Ω–µ—Ç–µ –æ—Ñ–∏—Ü–∏–∞–ª—å–Ω—É—é –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—é –∏–º–µ–Ω–Ω–æ –Ω–∞ –º–æ–¥–µ–ª—å Gemini 3.0 pro! –ü–æ—Å–ª–µ –∞–Ω–∞–ª–∏–∑–∞, –Ω–∞–ø–∏—à–∏ –∫–æ–¥ —Ä–µ—à–µ–Ω–∏—è –∏ —É–∫–∞–∂–∏, –∫—É–¥–∞ –µ–≥–æ –≤—Å—Ç–∞–≤–∏—Ç—å.""",
        "description": "–°–ª–æ–∂–Ω—ã–π –∑–∞–ø—Ä–æ—Å: –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è –Ω–æ–≤–æ–π –º–æ–¥–µ–ª–∏ —Å web_search",
        "expected_scope": "C",
    },
    {
        "id": "simple_bug",
        "query": "–ù–∞–π–¥–∏ –∏ –∏—Å–ø—Ä–∞–≤—å –±–∞–≥ –≤ —Ñ—É–Ω–∫—Ü–∏–∏ calculate_average –≤ —Ñ–∞–π–ª–µ app/utils/math_helpers.py - –æ–Ω–∞ –ø–∞–¥–∞–µ—Ç –ø—Ä–∏ –ø—É—Å—Ç–æ–º —Å–ø–∏—Å–∫–µ",
        "description": "–ü—Ä–æ—Å—Ç–æ–π –∑–∞–ø—Ä–æ—Å: –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ –±–∞–≥–∞",
        "expected_scope": "A",
    },
    {
        "id": "add_logging",
        "query": "–î–æ–±–∞–≤—å –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –≤–æ –≤—Å–µ –º–µ—Ç–æ–¥—ã –∫–ª–∞—Å—Å–∞ LLMClient –≤ —Ñ–∞–π–ª–µ app/llm/api_client.py",
        "description": "–°—Ä–µ–¥–Ω–∏–π –∑–∞–ø—Ä–æ—Å: –¥–æ–±–∞–≤–ª–µ–Ω–∏–µ —Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª—å–Ω–æ—Å—Ç–∏",
        "expected_scope": "B",
    },
]


# ============================================================================
# –î–ò–ê–ì–ù–û–°–¢–ò–ß–ï–°–ö–ò–ï –§–£–ù–ö–¶–ò–ò
# ============================================================================

def analyze_raw_response(raw_response: str) -> Dict[str, Any]:
    """
    –î–µ—Ç–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ —Å—ã—Ä–æ–≥–æ –æ—Ç–≤–µ—Ç–∞ –æ—Ä–∫–µ—Å—Ç—Ä–∞—Ç–æ—Ä–∞.
    
    Returns:
        Dict —Å –º–µ—Ç—Ä–∏–∫–∞–º–∏ –∏ —Ñ–ª–∞–≥–∞–º–∏ –ø—Ä–æ–±–ª–µ–º
    """
    analysis = {
        "total_length": len(raw_response),
        "line_count": raw_response.count('\n'),
        "has_analysis_header": bool(re.search(r'##\s*Analysis', raw_response, re.IGNORECASE)),
        "has_instruction_header": bool(re.search(r'##\s*Instruction', raw_response, re.IGNORECASE)),
        "has_scope": bool(re.search(r'\*\*SCOPE:\*\*', raw_response)),
        "has_task": bool(re.search(r'\*\*Task:\*\*', raw_response)),
        "has_file_block": bool(re.search(r'###\s*FILE:', raw_response)),
        "has_file_alt": bool(re.search(r'\*\*File:\*\*', raw_response)),
        "has_action_block": bool(re.search(r'####\s*(MODIFY_|ADD_|CREATE_|DELETE)', raw_response)),
        "has_changes": bool(re.search(r'\*\*Changes:\*\*', raw_response)),
        "truncation_markers": [],
        "potential_issues": [],
    }
    
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –æ–±—Ä–µ–∑–∞–Ω–∏–µ
    truncation_patterns = [
        (r'---\s*\n\s*#\s*\n\s*---', "–ü—É—Å—Ç–æ–π –∑–∞–≥–æ–ª–æ–≤–æ–∫ –º–µ–∂–¥—É —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª—è–º–∏"),
        (r'\*\*SCOPE:\*\*\s*[A-D]\s*\n\s*\*\*Task:\*\*[^\n]+\n\s*---\s*$', "–û–±—Ä–µ–∑–∞–Ω–æ –ø–æ—Å–ª–µ Task"),
        (r'###\s*FILE:[^\n]*\n\s*$', "–û–±—Ä–µ–∑–∞–Ω–æ –ø–æ—Å–ª–µ FILE"),
        (r'\n\s*$', None),  # –ü—Ä–æ—Å—Ç–æ –ø—É—Å—Ç–∞—è —Å—Ç—Ä–æ–∫–∞ –≤ –∫–æ–Ω—Ü–µ - –Ω–µ –ø—Ä–æ–±–ª–µ–º–∞
    ]
    
    for pattern, message in truncation_patterns:
        if message and re.search(pattern, raw_response):
            analysis["truncation_markers"].append(message)
    
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã
    if analysis["has_instruction_header"]:
        # –ù–∞–π–¥—ë–º –ø–æ–∑–∏—Ü–∏—é –Ω–∞—á–∞–ª–∞ –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏
        match = re.search(r'##\s*Instruction[^\n]*\n', raw_response, re.IGNORECASE)
        if match:
            instruction_start = match.end()
            instruction_content = raw_response[instruction_start:]
            analysis["instruction_content_length"] = len(instruction_content)
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –µ—Å—Ç—å –ª–∏ —Ä–µ–∞–ª—å–Ω—ã–π –∫–æ–Ω—Ç–µ–Ω—Ç
            if len(instruction_content.strip()) < 100:
                analysis["potential_issues"].append("–ò–Ω—Å—Ç—Ä—É–∫—Ü–∏—è —Å–ª–∏—à–∫–æ–º –∫–æ—Ä–æ—Ç–∫–∞—è (<100 —Å–∏–º–≤–æ–ª–æ–≤)")
    else:
        analysis["potential_issues"].append("–û—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç –∑–∞–≥–æ–ª–æ–≤–æ–∫ ## Instruction")
    
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ñ–æ—Ä–º–∞—Ç–∞
    if not analysis["has_scope"] and not analysis["has_task"]:
        analysis["potential_issues"].append("–ù–µ—Ç –Ω–∏ **SCOPE:**, –Ω–∏ **Task:**")
    
    if not analysis["has_file_block"] and not analysis["has_file_alt"]:
        analysis["potential_issues"].append("–ù–µ—Ç —É–∫–∞–∑–∞–Ω–∏—è —Ñ–∞–π–ª–∞ (–Ω–∏ ### FILE:, –Ω–∏ **File:**)")
    
    if not analysis["has_action_block"] and not analysis["has_changes"]:
        analysis["potential_issues"].append("–ù–µ—Ç –±–ª–æ–∫–æ–≤ –¥–µ–π—Å—Ç–≤–∏–π (#### ACTION –∏–ª–∏ **Changes:**)")
    
    return analysis


def extract_sections(raw_response: str) -> Dict[str, str]:
    """
    –ò–∑–≤–ª–µ–∫–∞–µ—Ç —Å–µ–∫—Ü–∏–∏ –∏–∑ —Å—ã—Ä–æ–≥–æ –æ—Ç–≤–µ—Ç–∞ –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è.
    """
    sections = {
        "before_analysis": "",
        "analysis": "",
        "instruction": "",
        "after_instruction": "",
    }
    
    # –ò—â–µ–º Analysis
    analysis_match = re.search(
        r'##\s*Analysis\s*\n(.*?)(?=##\s*Instruction|##\s*Setup|$)',
        raw_response,
        re.DOTALL | re.IGNORECASE
    )
    if analysis_match:
        sections["analysis"] = analysis_match.group(1).strip()
        sections["before_analysis"] = raw_response[:analysis_match.start()].strip()
    
    # –ò—â–µ–º Instruction
    instruction_match = re.search(
        r'##\s*Instruction[^\n]*\n(.*?)(?=##[^#]|$)',
        raw_response,
        re.DOTALL | re.IGNORECASE
    )
    if instruction_match:
        sections["instruction"] = instruction_match.group(1).strip()
    
    return sections


# ============================================================================
# –°–û–•–†–ê–ù–ï–ù–ò–ï –û–¢–ß–Å–¢–ê
# ============================================================================

def save_diagnostic_report(
    project_dir: str,
    query_id: str,
    user_query: str,
    model_used: str,
    raw_response: str,
    parsed_analysis: str,
    parsed_instruction: str,
    raw_analysis: Dict[str, Any],
    sections: Dict[str, str],
    tool_calls: List[Any],
    duration: float,
) -> Path:
    """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç –¥–µ—Ç–∞–ª—å–Ω—ã–π –¥–∏–∞–≥–Ω–æ—Å—Ç–∏—á–µ—Å–∫–∏–π –æ—Ç—á—ë—Ç"""
    
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    report_dir = Path(project_dir) / ".ai-agent" / "diagnostic_reports"
    report_dir.mkdir(parents=True, exist_ok=True)
    
    report_path = report_dir / f"orchestrator_diag_{query_id}_{timestamp}.md"
    
    lines = []
    
    # === –ó–ê–ì–û–õ–û–í–û–ö ===
    lines.append("# üî¨ –î–∏–∞–≥–Ω–æ—Å—Ç–∏—á–µ—Å–∫–∏–π –æ—Ç—á—ë—Ç Orchestrator")
    lines.append("")
    lines.append(f"**–î–∞—Ç–∞:** {datetime.now().strftime('%d.%m.%Y %H:%M:%S')}")
    lines.append(f"**–ü—Ä–æ–µ–∫—Ç:** `{project_dir}`")
    lines.append(f"**Query ID:** `{query_id}`")
    lines.append(f"**–ú–æ–¥–µ–ª—å:** `{model_used}`")
    lines.append(f"**–í—Ä–µ–º—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è:** {duration:.2f} —Å–µ–∫.")
    lines.append("")
    lines.append("---")
    lines.append("")
    
    # === –ó–ê–ü–†–û–° ===
    lines.append("## üìù –ó–∞–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è")
    lines.append("")
    lines.append("```")
    lines.append(user_query)
    lines.append("```")
    lines.append("")
    lines.append("---")
    lines.append("")
    
    # === –ú–ï–¢–†–ò–ö–ò –ê–ù–ê–õ–ò–ó–ê ===
    lines.append("## üìä –ú–µ—Ç—Ä–∏–∫–∏ —Å—ã—Ä–æ–≥–æ –æ—Ç–≤–µ—Ç–∞")
    lines.append("")
    lines.append("| –ú–µ—Ç—Ä–∏–∫–∞ | –ó–Ω–∞—á–µ–Ω–∏–µ |")
    lines.append("|---------|----------|")
    lines.append(f"| –û–±—â–∞—è –¥–ª–∏–Ω–∞ | {raw_analysis['total_length']} —Å–∏–º–≤–æ–ª–æ–≤ |")
    lines.append(f"| –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å—Ç—Ä–æ–∫ | {raw_analysis['line_count']} |")
    lines.append(f"| –ï—Å—Ç—å ## Analysis | {'‚úÖ' if raw_analysis['has_analysis_header'] else '‚ùå'} |")
    lines.append(f"| –ï—Å—Ç—å ## Instruction | {'‚úÖ' if raw_analysis['has_instruction_header'] else '‚ùå'} |")
    lines.append(f"| –ï—Å—Ç—å **SCOPE:** | {'‚úÖ' if raw_analysis['has_scope'] else '‚ùå'} |")
    lines.append(f"| –ï—Å—Ç—å **Task:** | {'‚úÖ' if raw_analysis['has_task'] else '‚ùå'} |")
    lines.append(f"| –ï—Å—Ç—å ### FILE: | {'‚úÖ' if raw_analysis['has_file_block'] else '‚ùå'} |")
    lines.append(f"| –ï—Å—Ç—å **File:** (alt) | {'‚úÖ' if raw_analysis['has_file_alt'] else '‚ùå'} |")
    lines.append(f"| –ï—Å—Ç—å #### ACTION | {'‚úÖ' if raw_analysis['has_action_block'] else '‚ùå'} |")
    lines.append(f"| –ï—Å—Ç—å **Changes:** | {'‚úÖ' if raw_analysis['has_changes'] else '‚ùå'} |")
    lines.append("")
    
    # === –ü–†–û–ë–õ–ï–ú–´ ===
    if raw_analysis["potential_issues"] or raw_analysis["truncation_markers"]:
        lines.append("## ‚ö†Ô∏è –û–±–Ω–∞—Ä—É–∂–µ–Ω–Ω—ã–µ –ø—Ä–æ–±–ª–µ–º—ã")
        lines.append("")
        for issue in raw_analysis["potential_issues"]:
            lines.append(f"- üî¥ {issue}")
        for marker in raw_analysis["truncation_markers"]:
            lines.append(f"- üü° –í–æ–∑–º–æ–∂–Ω–æ–µ –æ–±—Ä–µ–∑–∞–Ω–∏–µ: {marker}")
        lines.append("")
        lines.append("---")
        lines.append("")
    
    # === –°–†–ê–í–ù–ï–ù–ò–ï –î–õ–ò–ù ===
    lines.append("## üìè –°—Ä–∞–≤–Ω–µ–Ω–∏–µ –¥–ª–∏–Ω —Å–µ–∫—Ü–∏–π")
    lines.append("")
    lines.append("| –°–µ–∫—Ü–∏—è | –î–ª–∏–Ω–∞ (—Å—ã—Ä–æ–π) | –î–ª–∏–Ω–∞ (–ø–∞—Ä—Å–µ—Ä) | –†–∞–∑–Ω–∏—Ü–∞ |")
    lines.append("|--------|---------------|----------------|---------|")
    
    raw_analysis_len = len(sections.get("analysis", ""))
    raw_instruction_len = len(sections.get("instruction", ""))
    parsed_analysis_len = len(parsed_analysis)
    parsed_instruction_len = len(parsed_instruction)
    
    lines.append(f"| Analysis | {raw_analysis_len} | {parsed_analysis_len} | {raw_analysis_len - parsed_analysis_len} |")
    lines.append(f"| Instruction | {raw_instruction_len} | {parsed_instruction_len} | {raw_instruction_len - parsed_instruction_len} |")
    lines.append("")
    lines.append("---")
    lines.append("")
    
    # === –í–´–ó–û–í–´ –ò–ù–°–¢–†–£–ú–ï–ù–¢–û–í ===
    if tool_calls:
        lines.append("## üõ†Ô∏è –í—ã–∑–æ–≤—ã –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–≤")
        lines.append("")
        for i, tc in enumerate(tool_calls, 1):
            status = "‚úÖ" if getattr(tc, 'success', True) else "‚ùå"
            name = getattr(tc, 'name', 'unknown')
            args = getattr(tc, 'arguments', {})
            args_str = ", ".join(f"{k}={repr(v)[:50]}" for k, v in list(args.items())[:3])
            lines.append(f"{i}. {status} **{name}**(`{args_str}`)")
        lines.append("")
        lines.append("---")
        lines.append("")
    
    # === –°–´–†–û–ô –û–¢–í–ï–¢ (–ü–û–õ–ù–´–ô) ===
    lines.append("## üìÑ –°—ã—Ä–æ–π –æ—Ç–≤–µ—Ç –º–æ–¥–µ–ª–∏ (raw_response)")
    lines.append("")
    lines.append("```markdown")
    lines.append(raw_response)
    lines.append("```")
    lines.append("")
    lines.append("---")
    lines.append("")
    
    # === –†–ê–°–ü–ê–†–°–ï–ù–ù–´–ô ANALYSIS ===
    lines.append("## üîç –†–∞—Å–ø–∞—Ä—Å–µ–Ω–Ω—ã–π Analysis")
    lines.append("")
    lines.append(f"**–î–ª–∏–Ω–∞:** {parsed_analysis_len} —Å–∏–º–≤–æ–ª–æ–≤")
    lines.append("")
    lines.append("```markdown")
    lines.append(parsed_analysis if parsed_analysis else "[–ü–£–°–¢–û]")
    lines.append("```")
    lines.append("")
    lines.append("---")
    lines.append("")
    
    # === –†–ê–°–ü–ê–†–°–ï–ù–ù–ê–Ø INSTRUCTION ===
    lines.append("## üìã –†–∞—Å–ø–∞—Ä—Å–µ–Ω–Ω–∞—è Instruction")
    lines.append("")
    lines.append(f"**–î–ª–∏–Ω–∞:** {parsed_instruction_len} —Å–∏–º–≤–æ–ª–æ–≤")
    lines.append("")
    lines.append("```markdown")
    lines.append(parsed_instruction if parsed_instruction else "[–ü–£–°–¢–û]")
    lines.append("```")
    lines.append("")
    lines.append("---")
    lines.append("")
    
    # === –ò–ó–í–õ–ï–ß–Å–ù–ù–ê–Ø INSTRUCTION –ò–ó –°–´–†–û–ì–û ===
    lines.append("## üîß Instruction –∏–∑–≤–ª–µ—á—ë–Ω–Ω–∞—è –∏–∑ —Å—ã—Ä–æ–≥–æ –æ—Ç–≤–µ—Ç–∞ (–¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è)")
    lines.append("")
    lines.append(f"**–î–ª–∏–Ω–∞:** {raw_instruction_len} —Å–∏–º–≤–æ–ª–æ–≤")
    lines.append("")
    lines.append("```markdown")
    lines.append(sections.get("instruction", "[–ù–ï –ù–ê–ô–î–ï–ù–û]"))
    lines.append("```")
    lines.append("")
    
    # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ
    with open(report_path, 'w', encoding='utf-8') as f:
        f.write("\n".join(lines))
    
    return report_path


# ============================================================================
# –û–°–ù–û–í–ù–û–ô –¢–ï–°–¢
# ============================================================================

async def run_orchestrator_diagnostic(
    project_dir: str,
    query_info: Dict[str, str],
    model_override: Optional[str] = None,
) -> Dict[str, Any]:
    """
    –ó–∞–ø—É—Å–∫–∞–µ—Ç –æ—Ä–∫–µ—Å—Ç—Ä–∞—Ç–æ—Ä –∏ —Å–æ–±–∏—Ä–∞–µ—Ç –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫—É.
    """
    from config.settings import cfg
    from app.agents.pre_filter import pre_filter_chunks
    from app.agents.orchestrator import orchestrate
    from app.services.index_manager import load_semantic_index
    from app.services.project_map_builder import get_project_map_for_prompt
    from app.builders.semantic_index_builder import create_chunks_list_auto
    
    query_id = query_info["id"]
    user_query = query_info["query"]
    
    print_section(f"–¢–µ—Å—Ç: {query_info['description']}")
    print_info(f"Query ID: {query_id}")
    print(f"{Colors.DIM}–ó–∞–ø—Ä–æ—Å: {user_query[:100]}...{Colors.RESET}")
    
    result = {
        "query_id": query_id,
        "success": False,
        "error": None,
    }
    
    start_time = time.time()
    
    try:
        # –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö
        print_info("–ó–∞–≥—Ä—É–∑–∫–∞ –∏–Ω–¥–µ–∫—Å–∞...")
        index = load_semantic_index(project_dir)
        if index is None:
            raise ValueError("–ò–Ω–¥–µ–∫—Å –Ω–µ –Ω–∞–π–¥–µ–Ω")
        
        project_map = get_project_map_for_prompt(project_dir)
        compact_index = create_chunks_list_auto(index)
        
        # Pre-filter
        print_info("–ó–∞–ø—É—Å–∫ Pre-filter...")
        prefilter_result = await pre_filter_chunks(
            user_query=user_query,
            index=index,
            project_dir=project_dir,
        )
        print_success(f"–í—ã–±—Ä–∞–Ω–æ {len(prefilter_result.selected_chunks)} —á–∞–Ω–∫–æ–≤")
        
        # –í—ã–±–æ—Ä –º–æ–¥–µ–ª–∏
        if model_override:
            orchestrator_model = model_override
        else:
            from app.agents.router import route_request
            router_result = await route_request(user_query)
            orchestrator_model = router_result.orchestrator_model
        
        print_info(f"–ú–æ–¥–µ–ª—å: {cfg.get_model_display_name(orchestrator_model)}")
        
        # Orchestrate
        print_info("–ó–∞–ø—É—Å–∫ Orchestrator...")
        orchestrator_result = await orchestrate(
            user_query=user_query,
            selected_chunks=prefilter_result.selected_chunks,
            compact_index=compact_index,
            history=[],
            orchestrator_model=orchestrator_model,
            project_dir=project_dir,
            index=index,
            project_map=project_map,
        )
        
        duration = time.time() - start_time
        
        # –ê–Ω–∞–ª–∏–∑ —Å—ã—Ä–æ–≥–æ –æ—Ç–≤–µ—Ç–∞
        raw_response = orchestrator_result.raw_response
        raw_analysis = analyze_raw_response(raw_response)
        sections = extract_sections(raw_response)
        
        # –í—ã–≤–æ–¥ –º–µ—Ç—Ä–∏–∫
        print_section("–ú–µ—Ç—Ä–∏–∫–∏")
        print_metric("–î–ª–∏–Ω–∞ raw_response", raw_analysis["total_length"], threshold=500)
        print_metric("–î–ª–∏–Ω–∞ parsed analysis", len(orchestrator_result.analysis), threshold=100)
        print_metric("–î–ª–∏–Ω–∞ parsed instruction", len(orchestrator_result.instruction), threshold=50)
        print_metric("–ï—Å—Ç—å ## Instruction", "–î–∞" if raw_analysis["has_instruction_header"] else "–ù–µ—Ç")
        print_metric("–ï—Å—Ç—å ### FILE:", "–î–∞" if raw_analysis["has_file_block"] else "–ù–µ—Ç")
        print_metric("Tool calls", len(orchestrator_result.tool_calls))
        
        # –ü—Ä–æ–±–ª–µ–º—ã
        if raw_analysis["potential_issues"]:
            print_section("‚ö†Ô∏è –ü—Ä–æ–±–ª–µ–º—ã")
            for issue in raw_analysis["potential_issues"]:
                print_error(issue)
        
        if raw_analysis["truncation_markers"]:
            print_section("üî¥ –í–æ–∑–º–æ–∂–Ω–æ–µ –æ–±—Ä–µ–∑–∞–Ω–∏–µ")
            for marker in raw_analysis["truncation_markers"]:
                print_warning(marker)
        
        # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –æ—Ç—á—ë—Ç–∞
        report_path = save_diagnostic_report(
            project_dir=project_dir,
            query_id=query_id,
            user_query=user_query,
            model_used=cfg.get_model_display_name(orchestrator_model),
            raw_response=raw_response,
            parsed_analysis=orchestrator_result.analysis,
            parsed_instruction=orchestrator_result.instruction,
            raw_analysis=raw_analysis,
            sections=sections,
            tool_calls=orchestrator_result.tool_calls,
            duration=duration,
        )
        
        print_success(f"–û—Ç—á—ë—Ç —Å–æ—Ö—Ä–∞–Ω—ë–Ω: {report_path}")
        
        result["success"] = True
        result["report_path"] = str(report_path)
        result["metrics"] = raw_analysis
        result["duration"] = duration
        
    except Exception as e:
        result["error"] = str(e)
        print_error(f"–û—à–∏–±–∫–∞: {e}")
        import traceback
        traceback.print_exc()
    
    return result


# ============================================================================
# –ò–ù–¢–ï–†–ê–ö–¢–ò–í–ù–û–ï –ú–ï–ù–Æ
# ============================================================================

def select_directory() -> Optional[str]:
    """–í—ã–±–æ—Ä –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ –ø—Ä–æ–µ–∫—Ç–∞"""
    PROJECT_ROOT = Path(__file__).resolve().parent.parent
    
    suggestions = [
        str(PROJECT_ROOT),
        str(Path.cwd()),
    ]
    
    print(f"\n{Colors.CYAN}–í—ã–±–µ—Ä–∏—Ç–µ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –ø—Ä–æ–µ–∫—Ç–∞:{Colors.RESET}")
    for i, path in enumerate(suggestions, 1):
        exists = "‚úì" if Path(path).exists() else "‚úó"
        has_index = "üìë" if (Path(path) / ".ai-agent" / "semantic_index.json").exists() else "  "
        print(f"  {i}. [{exists}] {has_index} {path}")
    
    print(f"\n{Colors.DIM}–í–≤–µ–¥–∏—Ç–µ –Ω–æ–º–µ—Ä –∏–ª–∏ –ø–æ–ª–Ω—ã–π –ø—É—Ç—å:{Colors.RESET}")
    choice = input("> ").strip()
    
    if choice.isdigit() and 1 <= int(choice) <= len(suggestions):
        return suggestions[int(choice) - 1]
    elif choice:
        return choice
    return suggestions[0]


def select_model() -> Optional[str]:
    """–í—ã–±–æ—Ä –º–æ–¥–µ–ª–∏"""
    from config.settings import cfg
    
    print(f"\n{Colors.CYAN}–í—ã–±–µ—Ä–∏—Ç–µ –º–æ–¥–µ–ª—å Orchestrator:{Colors.RESET}")
    print("  0. –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π Router")
    
    models = cfg.get_available_orchestrator_models()
    for i, model in enumerate(models, 1):
        print(f"  {i}. {cfg.get_model_display_name(model)}")
    
    choice = input(f"\n{Colors.DIM}–í–∞—à –≤—ã–±–æ—Ä [0]:{Colors.RESET} ").strip()
    
    if choice == "" or choice == "0":
        return None
    
    if choice.isdigit() and 1 <= int(choice) <= len(models):
        return models[int(choice) - 1]
    
    return None


def select_queries() -> List[Dict[str, str]]:
    """–í—ã–±–æ—Ä —Ç–µ—Å—Ç–æ–≤—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤"""
    print(f"\n{Colors.CYAN}–í—ã–±–µ—Ä–∏—Ç–µ —Ç–µ—Å—Ç–æ–≤—ã–µ –∑–∞–ø—Ä–æ—Å—ã:{Colors.RESET}")
    print("  0. –í—Å–µ –∑–∞–ø—Ä–æ—Å—ã")
    
    for i, q in enumerate(TEST_QUERIES, 1):
        print(f"  {i}. [{q['id']}] {q['description']}")
    
    choice = input(f"\n{Colors.DIM}–í–∞—à –≤—ã–±–æ—Ä (—á–µ—Ä–µ–∑ –∑–∞–ø—è—Ç—É—é) [0]:{Colors.RESET} ").strip()
    
    if choice == "" or choice == "0":
        return TEST_QUERIES
    
    selected = []
    for idx in choice.split(","):
        idx = idx.strip()
        if idx.isdigit() and 1 <= int(idx) <= len(TEST_QUERIES):
            selected.append(TEST_QUERIES[int(idx) - 1])
    
    return selected if selected else TEST_QUERIES


# ============================================================================
# MAIN
# ============================================================================

async def main():
    print_header("üî¨ –î–ò–ê–ì–ù–û–°–¢–ò–ö–ê ORCHESTRATOR", "‚ïê")
    print("""
–≠—Ç–æ—Ç —Å–∫—Ä–∏–ø—Ç –∞–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç —Å—ã—Ä–æ–π –≤—ã–≤–æ–¥ Orchestrator –¥–ª—è –≤—ã—è–≤–ª–µ–Ω–∏—è –ø—Ä–æ–±–ª–µ–º
—Å –≥–µ–Ω–µ—Ä–∞—Ü–∏–µ–π –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–π.

–ß—Ç–æ –ø—Ä–æ–≤–µ—Ä—è–µ—Ç—Å—è:
‚Ä¢ –ü–æ–ª–Ω–æ—Ç–∞ —Å—ã—Ä–æ–≥–æ –æ—Ç–≤–µ—Ç–∞ (raw_response)
‚Ä¢ –ö–æ—Ä—Ä–µ–∫—Ç–Ω–æ—Å—Ç—å –ø–∞—Ä—Å–∏–Ω–≥–∞ —Å–µ–∫—Ü–∏–π
‚Ä¢ –ù–∞–ª–∏—á–∏–µ –≤—Å–µ—Ö –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã—Ö —ç–ª–µ–º–µ–Ω—Ç–æ–≤
‚Ä¢ –ü—Ä–∏–∑–Ω–∞–∫–∏ –æ–±—Ä–µ–∑–∞–Ω–∏—è –æ—Ç–≤–µ—Ç–∞
""")
    
    # –í—ã–±–æ—Ä –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤
    project_dir = select_directory()
    if not project_dir or not Path(project_dir).exists():
        print_error("–î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –Ω–µ –Ω–∞–π–¥–µ–Ω–∞")
        return
    
    model = select_model()
    queries = select_queries()
    
    print_header("–ó–ê–ü–£–°–ö –î–ò–ê–ì–ù–û–°–¢–ò–ö–ò")
    print_info(f"–ü—Ä–æ–µ–∫—Ç: {project_dir}")
    print_info(f"–ú–æ–¥–µ–ª—å: {model or 'Router (–∞–≤—Ç–æ)'}")
    print_info(f"–ó–∞–ø—Ä–æ—Å–æ–≤: {len(queries)}")
    
    # –ó–∞–ø—É—Å–∫ —Ç–µ—Å—Ç–æ–≤
    results = []
    for query_info in queries:
        result = await run_orchestrator_diagnostic(
            project_dir=project_dir,
            query_info=query_info,
            model_override=model,
        )
        results.append(result)
        print()
    
    # –ò—Ç–æ–≥–æ–≤–∞—è —Å–≤–æ–¥–∫–∞
    print_header("–ò–¢–û–ì–û–í–ê–Ø –°–í–û–î–ö–ê", "‚ïê")
    
    success_count = sum(1 for r in results if r["success"])
    print(f"\n–£—Å–ø–µ—à–Ω–æ: {success_count}/{len(results)}")
    
    for r in results:
        status = "‚úÖ" if r["success"] else "‚ùå"
        print(f"  {status} {r['query_id']}")
        if r.get("report_path"):
            print(f"      üìÑ {r['report_path']}")
        if r.get("error"):
            print(f"      ‚ùå {r['error']}")


if __name__ == "__main__":
    try:
        asyncio.run(main())
    except KeyboardInterrupt:
        print(f"\n{Colors.YELLOW}–ü—Ä–µ—Ä–≤–∞–Ω–æ{Colors.RESET}")
    except Exception as e:
        print(f"\n{Colors.RED}–û—à–∏–±–∫–∞: {e}{Colors.RESET}")
        import traceback
        traceback.print_exc()